{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuGPTvdf2zmN"
      },
      "source": [
        "# **Neural Networks & Intelligent Systems**\n",
        "## **ECE NTUA, Flow Y, 9th Semester, 2021-2022**\n",
        "### *Lab 1: Supervised Learning (Classification)*\n",
        "### Part 1: UCI Data\n",
        "\n",
        "#### Team 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFIHEckI3Ubc"
      },
      "source": [
        "## Installation of packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P-6ntfC6XZcT",
        "outputId": "277c7bcb-df59-4e84-bf03-198e45c5ee76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.1.3)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (4.28.2)\n",
            "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (6.3.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from setuptools-scm>=4->matplotlib) (57.4.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.1.3\n",
            "    Uninstalling matplotlib-3.1.3:\n",
            "      Successfully uninstalled matplotlib-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.1.3\n",
            "  Using cached matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.21.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.0\n",
            "    Uninstalling matplotlib-3.5.0:\n",
            "      Successfully uninstalled matplotlib-3.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.0.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install                --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn   --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy          --upgrade #upgrade numpy package\n",
        "!pip install                --upgrade matplotlib # Κάνουμε update την matplotlib\n",
        "!pip install matplotlib==3.1.3\n",
        "!pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAaUewae4aVN"
      },
      "source": [
        "## Εισαγωγή και επισκόπηση\n",
        "\n",
        "Η παρούσα εργασία αφορά την μελέτη και βελτιστοποίηση ταξινομητών σε σύνολα δεδομένων. Στο Part 1 μελετάται το dataset \"echocardiogram\" από το αποθετήριο UCI. Η εκπαιδευση και βελτιστοποίηση των ταξινομητών στο UCI dataset γίνεται αποκλειστικά με τις συναρτήσεις του skicit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7LKFppO48gy"
      },
      "source": [
        "#### Σύντομη παρουσίαση του dataset:\n",
        "\n",
        "Το Echocardiogram Data Set αφορά δεδομένα για την ταξινόμηση ασθενών που θα επιβιώσουν μετά από τουλάχιστον έναν χρόνο από κάποια καρδιακή προσβολή. Προέρχεται από τον donor Steven Salzberg και τον Collector Dr. Evlin Kinney. \n",
        "Όλοι οι ασθενείς που περιγράφονται υπέφερεαν από καρδιακή προσβολή κάποια στιγμή στο παρελθόν. Κάποιοι από αυτούς είναι ακόμα ζωντανοί ενώ κάποιοι άλλοι όχι. Οι παράμετροι survival και still-alive, όταν ληφθούν υπόψιν μαζί, δείχνουν εάν ο ασθενής επιβίωσε για τουλάχιστον ένα χρόνο μετά το συμβάν. Το πρόβλημα που τίθεται αφορά το κατά πόσο μπορεί κανείς να προβλέψει από τις άλλες παραμέτρους αν θα επιβιώσει ο ασθενής για τουλάχιστον ένα ακόμα χρόνο. Το πιο δύσκολο κομμάτι είναι η σωστή πρόβλεψη ότι ο ασθενής δεν θα επιβιώσει (μέρος της δυσκολίας είναι και το μέγεθος του data set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaqVInBo66r_"
      },
      "source": [
        "### Installation of libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUcq4hz_wNJv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OM_kqLX6-Ly"
      },
      "source": [
        "### Διάβασμα data set\n",
        "\n",
        "Παρακάτω, εκτός από το άνοιγμα του data set, δημιουργείται και ένα νέο αρχείο, το echocardiogram_new.data, το οποίο περιέχει όλη την πληροφορία του data set αλλά με την πρώτη γραμμή να είναι αριθμημένη για ευκολία στην χρήση στην συνέχεια. Επιπλέον, επειδή το data set έχει missing values, αντικαταστάθηκαν τα \"?\" με \"NaN\".\n",
        "\n",
        "**Προσοχή! Μετά την εκτέλεση του παρακάτω cell, θα πρέπει manually στο echocardiogram_new.data στην γραμμή 51 να σβηστεί στην αρχή το \",\" και μετά να σωθεί με Ctrl+S το αρχείο πριν συνεχίσει κανείς την εκτέλεση των cells.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QdBbeWJaOCv"
      },
      "outputs": [],
      "source": [
        "with open('echocardiogram.data') as data:\n",
        "  with open('echocardiogram_new.data', 'w') as data_new:\n",
        "    data_new.write(\"0,1,2,3,4,5,6,7,8,9,10,11,12\\n\")\n",
        "    \n",
        "    for line in data:\n",
        "      data_new.write(line.replace('?', 'NaN'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnGaMmf_78aZ"
      },
      "source": [
        "Μετά το διάβασμα, παρακάτω μπορεί να δει κανείς ενδεικτικά τις πρώτες γραμμές των δεδομένων καθώς και το μέγεθός του."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "qOJCHOxQb5kG",
        "outputId": "cb4b5068-2861-403c-c68b-3c212c676496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset dimensions: (132, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>9.000</td>\n",
              "      <td>4.600</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.380</td>\n",
              "      <td>6.000</td>\n",
              "      <td>4.100</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.588</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>4.000</td>\n",
              "      <td>3.420</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.253</td>\n",
              "      <td>12.062</td>\n",
              "      <td>4.603</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.788</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160</td>\n",
              "      <td>22.000</td>\n",
              "      <td>5.750</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.571</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1     2    3      4       5  ...     7     8      9    10   11   12\n",
              "0  11.0  0.0  71.0  0.0  0.260   9.000  ...  14.0  1.00  1.000  name  1.0  0.0\n",
              "1  19.0  0.0  72.0  0.0  0.380   6.000  ...  14.0  1.70  0.588  name  1.0  0.0\n",
              "2  16.0  0.0  55.0  0.0  0.260   4.000  ...  14.0  1.00  1.000  name  1.0  0.0\n",
              "3  57.0  0.0  60.0  0.0  0.253  12.062  ...  16.0  1.45  0.788  name  1.0  0.0\n",
              "4  19.0  1.0  57.0  0.0  0.160  22.000  ...  18.0  2.25  0.571  name  1.0  0.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('echocardiogram_new.data')\n",
        "\n",
        "print('Dataset dimensions:', dataset.shape)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TV3jgST9TGe"
      },
      "source": [
        "### Σχολιασμός για το Data set\n",
        "Στην συνέχεια, επειδή υπάρχουν missing values, μια στρατηγική είναι η αφαίρεση των δειγμάτων (γραμμές) που έχουν χαρακτηριστικά με απουσιάζουσες τιμές ή παρόμοια τα χαρακτηριστικά αν σε κάποια δείγματα απουσιάζουν.\n",
        "\n",
        "Επειδή τα datasets δημιουργούνται από μετρήσεις ή αντικείμενα του πραγματικού κόσμου, δεν είναι σπάνιο να υπάρχουν απουσιάζουσες τιμές κάποιων χαρακτηριστικών σε έναν αριθμό δειγμάτων. Ωστόσο, η είσοδος στους αλγόριθμους ΜΜ πρέπει να είναι πληρης. \n",
        "\n",
        "Παρατηρείται ότι στο CSV λείπουν τιμές οι οποίες αντικαταστάθηκαν με \"NaN\" (\"Not A Number\") όπως αναφέρθηκε παραπάνω.\n",
        "\n",
        "Σημειώνεται ότι αυτή μεθοδολογία είναι η μόνη μορφή προεπεξεργασίας που καλύτερο είναι να γίνει πριν τον διαχωρισμό σε train και test.\n",
        "\n",
        "Μπορεί αυτή η προσέγγιση να είναι μοιάζει απλή, ωστόσο ειδικά αν απουσιάζουν πολλές τιμές, συνήθως δεν είναι θεμιτός να θυσιαστούν δεδομένα (δείγματα) ούτε να αφαιρεθούν χαρακτηριστικά που μπορεί να περιλαμβάνουν σημαντική πληροφορία για το διαχωρισμό των κλάσσεων."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UY0GoC-3kf"
      },
      "source": [
        "### Από το FAQ: \n",
        "Το χαρακτηριστικό εξοδου (η κλάση) είναι το 13ο “alive-at-1” οπότε διατηρούνται μόνο όσα δείγματα δεν έχουν “?” στο\n",
        "“alive-at-1”. Τα χαρακτηριστικά είναι τα 3 έως 9 (τα υπόλοιπα μπορούν να αγνοηθούν). Η πρόβλεψη μπορεί να\n",
        "γίνει και με τα χαρακτηριστικά 1-9 (όπως διατυπώθηκε αρχικά) απλά θα δίνει πολύ υψηλές τιμές (που δεν\n",
        "προσφέρονται για πολύ περεταίρω βελτιστοποίηση) γιατί υπάρχει μεγάλη συσχέτιση (αν και όχι απόλυτη) μεταξύ\n",
        "των χαρακτηριστικών 1 και 2 και της μεταβλητής εξόδου. Οι κολόνες 1-9 είναι τα χαρακτηριστικά εισόδου (έχουμε αφαιρέσει τα 3 άχρηστα\n",
        "αρχικά χαρακτηριστικά) και η 10η κολόνα είναι η έξοδος. Τιμές κοντά στο -1 ή στο 1 δείχνουν υψηλή συσχέτιση,\n",
        "αντίστροφη (-1) ή ανάλογη (1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8sah6Do543e"
      },
      "source": [
        "### Περαιτέρω Σχολιασμός\n",
        "\n",
        "Λαμβάνοντας υπόψιν τα παραπάνω, αρχικά τα missing δεδομένα διαγράφηκαν τελείως και προέκυψαν 61 rows. Όμως, για καλύτερα αποτελέσματα προτιμήθηκε με βάση τις οδηγίες του FAQ η μέθοδος που φαίνεται στην συνέχεια ώστε να διατηρηθούν 74 rows χρησιμοποιώντας και τον μετασχηματιστή “[Imputer](http://scikit-learn.org/stable/modules/impute.html)” του scikit learn που αντικαθιστά κάθε απουσιάζουσα τιμή χαρακτηριστικού με τη μέση τιμή (συνεχείς μεταβλητές) ή την πιο συχνή τιμή (κατηγορικές μεταβλητές) του χαρακτηριστικού στο train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QUitA69-NXP"
      },
      "source": [
        "Έτσι, σύμφωνα με τα προηγούμενα, στο ακόλουθο cell φαίνεται η διαδικασία με την οποία μετονομάστηκε το NaN σε null σε ολες τις στήλες εκτός της 12ης και μετά ενώθηκε ξανά."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UdAcKifUfvDP",
        "outputId": "9622daaf-7b61-493c-fc13-8cdd9a6751a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>9</td>\n",
              "      <td>4.6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>name</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0.38</td>\n",
              "      <td>6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.588</td>\n",
              "      <td>name</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>4</td>\n",
              "      <td>3.42</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>name</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0.253</td>\n",
              "      <td>12.062</td>\n",
              "      <td>4.603</td>\n",
              "      <td>16</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.788</td>\n",
              "      <td>name</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.16</td>\n",
              "      <td>22</td>\n",
              "      <td>5.75</td>\n",
              "      <td>18</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.571</td>\n",
              "      <td>name</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>1.25</td>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.52</td>\n",
              "      <td>18.16</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.857</td>\n",
              "      <td>name</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>14.3</td>\n",
              "      <td>5.49</td>\n",
              "      <td>13.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.643</td>\n",
              "      <td>name</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.228</td>\n",
              "      <td>9.7</td>\n",
              "      <td>4.29</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.786</td>\n",
              "      <td>name</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.75</td>\n",
              "      <td>1</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>40</td>\n",
              "      <td>6.23</td>\n",
              "      <td>14</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.714</td>\n",
              "      <td>name</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>7.6</td>\n",
              "      <td>4.42</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>name</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0  1   2  3      4       5      6      7     8      9    10 11   12\n",
              "0      11  0  71  0   0.26       9    4.6     14     1      1  name  1  0.0\n",
              "1      19  0  72  0   0.38       6    4.1     14   1.7  0.588  name  1  0.0\n",
              "2      16  0  55  0   0.26       4   3.42     14     1      1  name  1  0.0\n",
              "3      57  0  60  0  0.253  12.062  4.603     16  1.45  0.788  name  1  0.0\n",
              "4      19  1  57  0   0.16      22   5.75     18  2.25  0.571  name  1  0.0\n",
              "..    ... ..  .. ..    ...     ...    ...    ...   ...    ...   ... ..  ...\n",
              "104  1.25  1  63  0    0.3     6.9   3.52  18.16  1.51  0.857  name  2  1.0\n",
              "105    24  0  59  0   0.17    14.3   5.49   13.5   1.5  0.643  name  2  0.0\n",
              "106    25  0  57  0  0.228     9.7   4.29     11     1  0.786  name  2  0.0\n",
              "108  0.75  1  78  0   0.23      40   6.23     14   1.4  0.714  name  2  1.0\n",
              "109     3  1  62  0   0.26     7.6   4.42     14     1      1  name  2  1.0\n",
              "\n",
              "[74 rows x 13 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_n = pd.concat([dataset.iloc[:, :12].replace(np.NaN, 'null'), dataset.iloc[:, [12]]], axis=1).dropna(axis=0)\n",
        "\n",
        "dataset_n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqUfI1xi6wlA"
      },
      "source": [
        "Έπειτα, αντικαταστάθηκε το null ξανά σε NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MGb-3Nwz8_B2",
        "outputId": "f83ea042-4f3f-4693-819f-48a723a5928e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>9.000</td>\n",
              "      <td>4.600</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.380</td>\n",
              "      <td>6.000</td>\n",
              "      <td>4.100</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.588</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>4.000</td>\n",
              "      <td>3.420</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.253</td>\n",
              "      <td>12.062</td>\n",
              "      <td>4.603</td>\n",
              "      <td>16.00</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.788</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160</td>\n",
              "      <td>22.000</td>\n",
              "      <td>5.750</td>\n",
              "      <td>18.00</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.571</td>\n",
              "      <td>name</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300</td>\n",
              "      <td>6.900</td>\n",
              "      <td>3.520</td>\n",
              "      <td>18.16</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.857</td>\n",
              "      <td>name</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>24.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170</td>\n",
              "      <td>14.300</td>\n",
              "      <td>5.490</td>\n",
              "      <td>13.50</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.643</td>\n",
              "      <td>name</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>25.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.228</td>\n",
              "      <td>9.700</td>\n",
              "      <td>4.290</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.786</td>\n",
              "      <td>name</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.230</td>\n",
              "      <td>40.000</td>\n",
              "      <td>6.230</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.714</td>\n",
              "      <td>name</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>3.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>7.600</td>\n",
              "      <td>4.420</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>name</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1     2    3      4       5  ...      7     8      9    10   11   12\n",
              "0    11.00  0.0  71.0  0.0  0.260   9.000  ...  14.00  1.00  1.000  name  1.0  0.0\n",
              "1    19.00  0.0  72.0  0.0  0.380   6.000  ...  14.00  1.70  0.588  name  1.0  0.0\n",
              "2    16.00  0.0  55.0  0.0  0.260   4.000  ...  14.00  1.00  1.000  name  1.0  0.0\n",
              "3    57.00  0.0  60.0  0.0  0.253  12.062  ...  16.00  1.45  0.788  name  1.0  0.0\n",
              "4    19.00  1.0  57.0  0.0  0.160  22.000  ...  18.00  2.25  0.571  name  1.0  0.0\n",
              "..     ...  ...   ...  ...    ...     ...  ...    ...   ...    ...   ...  ...  ...\n",
              "104   1.25  1.0  63.0  0.0  0.300   6.900  ...  18.16  1.51  0.857  name  2.0  1.0\n",
              "105  24.00  0.0  59.0  0.0  0.170  14.300  ...  13.50  1.50  0.643  name  2.0  0.0\n",
              "106  25.00  0.0  57.0  0.0  0.228   9.700  ...  11.00  1.00  0.786  name  2.0  0.0\n",
              "108   0.75  1.0  78.0  0.0  0.230  40.000  ...  14.00  1.40  0.714  name  2.0  1.0\n",
              "109   3.00  1.0  62.0  0.0  0.260   7.600  ...  14.00  1.00  1.000  name  2.0  1.0\n",
              "\n",
              "[74 rows x 13 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_clear = dataset_n.replace('null', np.NaN)\n",
        "\n",
        "dataset_clear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozqsKbi963dU"
      },
      "source": [
        "Ύστερα, απομονώθηκαν τα features που χρειάζονται με βάση το FAQ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Mj9Cn8Pyck1v",
        "outputId": "a2566789-961e-47f6-a9fe-4bbe8eba4f30"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>9.000</td>\n",
              "      <td>4.600</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.380</td>\n",
              "      <td>6.000</td>\n",
              "      <td>4.100</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>4.000</td>\n",
              "      <td>3.420</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.253</td>\n",
              "      <td>12.062</td>\n",
              "      <td>4.603</td>\n",
              "      <td>16.00</td>\n",
              "      <td>1.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160</td>\n",
              "      <td>22.000</td>\n",
              "      <td>5.750</td>\n",
              "      <td>18.00</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300</td>\n",
              "      <td>6.900</td>\n",
              "      <td>3.520</td>\n",
              "      <td>18.16</td>\n",
              "      <td>1.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170</td>\n",
              "      <td>14.300</td>\n",
              "      <td>5.490</td>\n",
              "      <td>13.50</td>\n",
              "      <td>1.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.228</td>\n",
              "      <td>9.700</td>\n",
              "      <td>4.290</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>78.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.230</td>\n",
              "      <td>40.000</td>\n",
              "      <td>6.230</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>7.600</td>\n",
              "      <td>4.420</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        2    3      4       5      6      7     8\n",
              "0    71.0  0.0  0.260   9.000  4.600  14.00  1.00\n",
              "1    72.0  0.0  0.380   6.000  4.100  14.00  1.70\n",
              "2    55.0  0.0  0.260   4.000  3.420  14.00  1.00\n",
              "3    60.0  0.0  0.253  12.062  4.603  16.00  1.45\n",
              "4    57.0  0.0  0.160  22.000  5.750  18.00  2.25\n",
              "..    ...  ...    ...     ...    ...    ...   ...\n",
              "104  63.0  0.0  0.300   6.900  3.520  18.16  1.51\n",
              "105  59.0  0.0  0.170  14.300  5.490  13.50  1.50\n",
              "106  57.0  0.0  0.228   9.700  4.290  11.00  1.00\n",
              "108  78.0  0.0  0.230  40.000  6.230  14.00  1.40\n",
              "109  62.0  0.0  0.260   7.600  4.420  14.00  1.00\n",
              "\n",
              "[74 rows x 7 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = dataset_clear.iloc[:, 2:9]\n",
        "\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYxsDJXDgpFN"
      },
      "source": [
        "Τελικά, για τις απουσιάζουσες πληροφορίες γίνεται ο υπολογισμός της mean με τον imputer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "Rl4RioL993ZZ",
        "outputId": "34aeb588-8a8d-459d-9f96-7929949955b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>3.630000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.222000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>4.700000</td>\n",
              "      <td>4.490000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>17.500000</td>\n",
              "      <td>4.270000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>12.576636</td>\n",
              "      <td>3.590000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>81.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>12.576636</td>\n",
              "      <td>4.785912</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>21.300000</td>\n",
              "      <td>6.290000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>63.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.219057</td>\n",
              "      <td>12.576636</td>\n",
              "      <td>4.785912</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>15.348082</td>\n",
              "      <td>1.433795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>12.576636</td>\n",
              "      <td>4.785912</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>3.490000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>5.650000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>66.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>15.600000</td>\n",
              "      <td>6.150000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>63.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.570000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>18.600000</td>\n",
              "      <td>4.370000</td>\n",
              "      <td>12.330000</td>\n",
              "      <td>1.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>11.900000</td>\n",
              "      <td>5.150000</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>1.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.020000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>13.200000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>5.570000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>65.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>5.780000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>5.620000</td>\n",
              "      <td>13.670000</td>\n",
              "      <td>1.367000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>86.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>12.200000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>4.720000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>4.310000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217000</td>\n",
              "      <td>17.900000</td>\n",
              "      <td>4.540000</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>1.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>64.349712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>19.400000</td>\n",
              "      <td>4.770000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>2.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>4.580000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>16.800000</td>\n",
              "      <td>4.160000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.440000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.360000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            2    3         4          5         6          7         8\n",
              "40  54.000000  0.0  0.350000   9.300000  3.630000  11.000000  1.222000\n",
              "41  70.000000  1.0  0.270000   4.700000  4.490000  22.000000  2.000000\n",
              "42  79.000000  0.0  0.150000  17.500000  4.270000  13.000000  1.300000\n",
              "43  56.000000  0.0  0.330000  12.576636  3.590000  14.000000  1.000000\n",
              "46  81.000000  0.0  0.120000  12.576636  4.785912   9.000000  1.250000\n",
              "47  59.000000  0.0  0.030000  21.300000  6.290000  17.000000  1.310000\n",
              "48  63.000000  1.0  0.219057  12.576636  4.785912  23.000000  2.300000\n",
              "50  56.000000  1.0  0.040000  14.000000  5.000000  15.348082  1.433795\n",
              "51  61.000000  1.0  0.270000  12.576636  4.785912   9.000000  1.500000\n",
              "53  58.000000  0.0  0.300000   9.400000  3.490000  14.000000  1.000000\n",
              "54  60.000000  0.0  0.010000  24.600000  5.650000  39.000000  3.000000\n",
              "55  66.000000  0.0  0.290000  15.600000  6.150000  14.000000  1.000000\n",
              "56  63.000000  0.0  0.150000  13.000000  4.570000  13.000000  1.080000\n",
              "57  57.000000  0.0  0.130000  18.600000  4.370000  12.330000  1.370000\n",
              "58  70.000000  0.0  0.100000   9.800000  5.300000  23.000000  2.300000\n",
              "60  79.000000  0.0  0.170000  11.900000  5.150000  10.500000  1.050000\n",
              "62  72.000000  0.0  0.187000  12.000000  5.020000  13.000000  1.180000\n",
              "65  51.000000  0.0  0.160000  13.200000  5.260000  11.000000  1.000000\n",
              "67  70.000000  1.0  0.250000   9.700000  5.570000   5.500000  1.100000\n",
              "68  65.000000  0.0  0.360000   8.800000  5.780000  12.000000  1.000000\n",
              "69  78.000000  0.0  0.060000  16.100000  5.620000  13.670000  1.367000\n",
              "70  86.000000  0.0  0.225000  12.200000  5.200000  24.000000  2.180000\n",
              "71  56.000000  0.0  0.250000  11.000000  4.720000  11.000000  1.000000\n",
              "72  60.000000  0.0  0.120000  10.200000  4.310000  15.000000  1.670000\n",
              "73  59.000000  0.0  0.290000   7.500000  4.750000  13.000000  1.080000\n",
              "75  54.000000  0.0  0.217000  17.900000  4.540000  16.500000  1.180000\n",
              "77  64.349712  0.0  0.260000  19.400000  4.770000  21.000000  2.100000\n",
              "78  64.000000  0.0  0.200000   7.100000  4.580000  14.000000  1.000000\n",
              "81  54.000000  1.0  0.070000  16.800000  4.160000  18.000000  1.500000\n",
              "83  78.000000  0.0  0.050000  10.000000  4.440000  15.000000  1.360000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "imp = SimpleImputer(missing_values = np.NaN, strategy='mean')\n",
        "\n",
        "features_clear = pd.DataFrame(imp.fit_transform(features))\n",
        "features_clear.columns = features.columns\n",
        "features_clear.index = features.index\n",
        "\n",
        "# ενδεικτικά, τυπώνονται κάποιες σειρές\n",
        "features_clear.iloc[30:60, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T4wxFHZ_x46"
      },
      "source": [
        "Μετά, γίνεται ο διαχωρισμός των features και labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK9KA47ddxQW",
        "outputId": "7e346dc4-6edb-4ac2-bb75-94be285b84bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[7.10000000e+01, 0.00000000e+00, 2.60000000e-01, 9.00000000e+00,\n",
              "        4.60000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [7.20000000e+01, 0.00000000e+00, 3.80000000e-01, 6.00000000e+00,\n",
              "        4.10000000e+00, 1.40000000e+01, 1.70000000e+00],\n",
              "       [5.50000000e+01, 0.00000000e+00, 2.60000000e-01, 4.00000000e+00,\n",
              "        3.42000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [6.00000000e+01, 0.00000000e+00, 2.53000000e-01, 1.20620000e+01,\n",
              "        4.60300000e+00, 1.60000000e+01, 1.45000000e+00],\n",
              "       [5.70000000e+01, 0.00000000e+00, 1.60000000e-01, 2.20000000e+01,\n",
              "        5.75000000e+00, 1.80000000e+01, 2.25000000e+00],\n",
              "       [6.80000000e+01, 0.00000000e+00, 2.60000000e-01, 5.00000000e+00,\n",
              "        4.31000000e+00, 1.20000000e+01, 1.00000000e+00],\n",
              "       [6.20000000e+01, 0.00000000e+00, 2.30000000e-01, 3.10000000e+01,\n",
              "        5.43000000e+00, 2.25000000e+01, 1.87500000e+00],\n",
              "       [6.00000000e+01, 0.00000000e+00, 3.30000000e-01, 8.00000000e+00,\n",
              "        5.25000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [4.60000000e+01, 0.00000000e+00, 3.40000000e-01, 0.00000000e+00,\n",
              "        5.09000000e+00, 1.60000000e+01, 1.14000000e+00],\n",
              "       [5.40000000e+01, 0.00000000e+00, 1.40000000e-01, 1.30000000e+01,\n",
              "        4.49000000e+00, 1.55000000e+01, 1.19000000e+00],\n",
              "       [7.70000000e+01, 0.00000000e+00, 1.30000000e-01, 1.60000000e+01,\n",
              "        4.23000000e+00, 1.80000000e+01, 1.80000000e+00],\n",
              "       [6.20000000e+01, 1.00000000e+00, 4.50000000e-01, 9.00000000e+00,\n",
              "        3.60000000e+00, 1.60000000e+01, 1.14000000e+00],\n",
              "       [7.30000000e+01, 0.00000000e+00, 3.30000000e-01, 6.00000000e+00,\n",
              "        4.00000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [6.00000000e+01, 0.00000000e+00, 1.50000000e-01, 1.00000000e+01,\n",
              "        3.73000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [6.20000000e+01, 0.00000000e+00, 1.20000000e-01, 2.30000000e+01,\n",
              "        5.80000000e+00, 1.16700000e+01, 2.33000000e+00],\n",
              "       [5.50000000e+01, 1.00000000e+00, 2.50000000e-01, 1.20630000e+01,\n",
              "        4.29000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [6.90000000e+01, 1.00000000e+00, 2.60000000e-01, 1.10000000e+01,\n",
              "        4.65000000e+00, 1.80000000e+01, 1.64000000e+00],\n",
              "       [6.25290000e+01, 1.00000000e+00, 7.00000000e-02, 2.00000000e+01,\n",
              "        5.20000000e+00, 2.40000000e+01, 2.00000000e+00],\n",
              "       [6.60000000e+01, 0.00000000e+00, 9.00000000e-02, 1.70000000e+01,\n",
              "        5.81900000e+00, 8.00000000e+00, 1.33300000e+00],\n",
              "       [6.60000000e+01, 1.00000000e+00, 2.20000000e-01, 1.50000000e+01,\n",
              "        5.40000000e+00, 2.70000000e+01, 2.25000000e+00],\n",
              "       [6.90000000e+01, 0.00000000e+00, 1.50000000e-01, 1.20000000e+01,\n",
              "        5.39000000e+00, 1.95000000e+01, 1.62500000e+00],\n",
              "       [8.50000000e+01, 1.00000000e+00, 1.80000000e-01, 1.90000000e+01,\n",
              "        5.46000000e+00, 1.38300000e+01, 1.38000000e+00],\n",
              "       [7.30000000e+01, 0.00000000e+00, 2.30000000e-01, 1.27330000e+01,\n",
              "        6.06000000e+00, 7.50000000e+00, 1.50000000e+00],\n",
              "       [7.10000000e+01, 0.00000000e+00, 1.70000000e-01, 0.00000000e+00,\n",
              "        4.65000000e+00, 8.00000000e+00, 1.00000000e+00],\n",
              "       [5.50000000e+01, 1.00000000e+00, 2.10000000e-01, 4.20000000e+00,\n",
              "        4.16000000e+00, 1.40000000e+01, 1.56000000e+00],\n",
              "       [6.30000000e+01, 0.00000000e+00, 2.19057143e-01, 1.00000000e+01,\n",
              "        4.78591176e+00, 1.40000000e+01, 1.17000000e+00],\n",
              "       [6.10000000e+01, 0.00000000e+00, 6.10000000e-01, 1.31000000e+01,\n",
              "        4.07000000e+00, 1.30000000e+01, 1.62500000e+00],\n",
              "       [6.30000000e+01, 1.00000000e+00, 2.19057143e-01, 1.25766364e+01,\n",
              "        5.31000000e+00, 5.00000000e+00, 1.00000000e+00],\n",
              "       [6.50000000e+01, 0.00000000e+00, 6.00000000e-02, 2.36000000e+01,\n",
              "        4.78591176e+00, 2.15000000e+01, 2.15000000e+00],\n",
              "       [6.80000000e+01, 0.00000000e+00, 5.10000000e-01, 1.25766364e+01,\n",
              "        3.88000000e+00, 1.50000000e+01, 1.67000000e+00],\n",
              "       [5.40000000e+01, 0.00000000e+00, 3.50000000e-01, 9.30000000e+00,\n",
              "        3.63000000e+00, 1.10000000e+01, 1.22200000e+00],\n",
              "       [7.00000000e+01, 1.00000000e+00, 2.70000000e-01, 4.70000000e+00,\n",
              "        4.49000000e+00, 2.20000000e+01, 2.00000000e+00],\n",
              "       [7.90000000e+01, 0.00000000e+00, 1.50000000e-01, 1.75000000e+01,\n",
              "        4.27000000e+00, 1.30000000e+01, 1.30000000e+00],\n",
              "       [5.60000000e+01, 0.00000000e+00, 3.30000000e-01, 1.25766364e+01,\n",
              "        3.59000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [8.10000000e+01, 0.00000000e+00, 1.20000000e-01, 1.25766364e+01,\n",
              "        4.78591176e+00, 9.00000000e+00, 1.25000000e+00],\n",
              "       [5.90000000e+01, 0.00000000e+00, 3.00000000e-02, 2.13000000e+01,\n",
              "        6.29000000e+00, 1.70000000e+01, 1.31000000e+00],\n",
              "       [6.30000000e+01, 1.00000000e+00, 2.19057143e-01, 1.25766364e+01,\n",
              "        4.78591176e+00, 2.30000000e+01, 2.30000000e+00],\n",
              "       [5.60000000e+01, 1.00000000e+00, 4.00000000e-02, 1.40000000e+01,\n",
              "        5.00000000e+00, 1.53480822e+01, 1.43379452e+00],\n",
              "       [6.10000000e+01, 1.00000000e+00, 2.70000000e-01, 1.25766364e+01,\n",
              "        4.78591176e+00, 9.00000000e+00, 1.50000000e+00],\n",
              "       [5.80000000e+01, 0.00000000e+00, 3.00000000e-01, 9.40000000e+00,\n",
              "        3.49000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [6.00000000e+01, 0.00000000e+00, 1.00000000e-02, 2.46000000e+01,\n",
              "        5.65000000e+00, 3.90000000e+01, 3.00000000e+00],\n",
              "       [6.60000000e+01, 0.00000000e+00, 2.90000000e-01, 1.56000000e+01,\n",
              "        6.15000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [6.30000000e+01, 0.00000000e+00, 1.50000000e-01, 1.30000000e+01,\n",
              "        4.57000000e+00, 1.30000000e+01, 1.08000000e+00],\n",
              "       [5.70000000e+01, 0.00000000e+00, 1.30000000e-01, 1.86000000e+01,\n",
              "        4.37000000e+00, 1.23300000e+01, 1.37000000e+00],\n",
              "       [7.00000000e+01, 0.00000000e+00, 1.00000000e-01, 9.80000000e+00,\n",
              "        5.30000000e+00, 2.30000000e+01, 2.30000000e+00],\n",
              "       [7.90000000e+01, 0.00000000e+00, 1.70000000e-01, 1.19000000e+01,\n",
              "        5.15000000e+00, 1.05000000e+01, 1.05000000e+00],\n",
              "       [7.20000000e+01, 0.00000000e+00, 1.87000000e-01, 1.20000000e+01,\n",
              "        5.02000000e+00, 1.30000000e+01, 1.18000000e+00],\n",
              "       [5.10000000e+01, 0.00000000e+00, 1.60000000e-01, 1.32000000e+01,\n",
              "        5.26000000e+00, 1.10000000e+01, 1.00000000e+00],\n",
              "       [7.00000000e+01, 1.00000000e+00, 2.50000000e-01, 9.70000000e+00,\n",
              "        5.57000000e+00, 5.50000000e+00, 1.10000000e+00],\n",
              "       [6.50000000e+01, 0.00000000e+00, 3.60000000e-01, 8.80000000e+00,\n",
              "        5.78000000e+00, 1.20000000e+01, 1.00000000e+00],\n",
              "       [7.80000000e+01, 0.00000000e+00, 6.00000000e-02, 1.61000000e+01,\n",
              "        5.62000000e+00, 1.36700000e+01, 1.36700000e+00],\n",
              "       [8.60000000e+01, 0.00000000e+00, 2.25000000e-01, 1.22000000e+01,\n",
              "        5.20000000e+00, 2.40000000e+01, 2.18000000e+00],\n",
              "       [5.60000000e+01, 0.00000000e+00, 2.50000000e-01, 1.10000000e+01,\n",
              "        4.72000000e+00, 1.10000000e+01, 1.00000000e+00],\n",
              "       [6.00000000e+01, 0.00000000e+00, 1.20000000e-01, 1.02000000e+01,\n",
              "        4.31000000e+00, 1.50000000e+01, 1.67000000e+00],\n",
              "       [5.90000000e+01, 0.00000000e+00, 2.90000000e-01, 7.50000000e+00,\n",
              "        4.75000000e+00, 1.30000000e+01, 1.08000000e+00],\n",
              "       [5.40000000e+01, 0.00000000e+00, 2.17000000e-01, 1.79000000e+01,\n",
              "        4.54000000e+00, 1.65000000e+01, 1.18000000e+00],\n",
              "       [6.43497123e+01, 0.00000000e+00, 2.60000000e-01, 1.94000000e+01,\n",
              "        4.77000000e+00, 2.10000000e+01, 2.10000000e+00],\n",
              "       [6.40000000e+01, 0.00000000e+00, 2.00000000e-01, 7.10000000e+00,\n",
              "        4.58000000e+00, 1.40000000e+01, 1.00000000e+00],\n",
              "       [5.40000000e+01, 1.00000000e+00, 7.00000000e-02, 1.68000000e+01,\n",
              "        4.16000000e+00, 1.80000000e+01, 1.50000000e+00],\n",
              "       [7.80000000e+01, 0.00000000e+00, 5.00000000e-02, 1.00000000e+01,\n",
              "        4.44000000e+00, 1.50000000e+01, 1.36000000e+00],\n",
              "       [6.10000000e+01, 0.00000000e+00, 2.19057143e-01, 1.25766364e+01,\n",
              "        4.78591176e+00, 2.80000000e+01, 2.33000000e+00],\n",
              "       [5.50000000e+01, 0.00000000e+00, 2.80000000e-01, 5.50000000e+00,\n",
              "        4.48000000e+00, 2.20000000e+01, 1.83000000e+00],\n",
              "       [5.90000000e+01, 0.00000000e+00, 3.44000000e-01, 9.10000000e+00,\n",
              "        4.04000000e+00, 9.00000000e+00, 1.00000000e+00],\n",
              "       [6.10000000e+01, 0.00000000e+00, 2.00000000e-01, 9.40000000e+00,\n",
              "        4.02000000e+00, 1.56700000e+01, 1.42000000e+00],\n",
              "       [7.40000000e+01, 0.00000000e+00, 2.00000000e-01, 4.80000000e+00,\n",
              "        4.56000000e+00, 1.25000000e+01, 1.04000000e+00],\n",
              "       [6.50000000e+01, 1.00000000e+00, 1.60000000e-01, 8.50000000e+00,\n",
              "        5.47000000e+00, 1.60000000e+01, 1.45000000e+00],\n",
              "       [5.80000000e+01, 0.00000000e+00, 1.70000000e-01, 2.89000000e+01,\n",
              "        6.73000000e+00, 2.60800000e+01, 2.01000000e+00],\n",
              "       [6.60000000e+01, 0.00000000e+00, 2.00000000e-01, 1.25766364e+01,\n",
              "        4.23000000e+00, 1.20000000e+01, 1.00000000e+00],\n",
              "       [7.00000000e+01, 0.00000000e+00, 3.80000000e-01, 0.00000000e+00,\n",
              "        4.55000000e+00, 1.00000000e+01, 1.00000000e+00],\n",
              "       [6.30000000e+01, 0.00000000e+00, 3.00000000e-01, 6.90000000e+00,\n",
              "        3.52000000e+00, 1.81600000e+01, 1.51000000e+00],\n",
              "       [5.90000000e+01, 0.00000000e+00, 1.70000000e-01, 1.43000000e+01,\n",
              "        5.49000000e+00, 1.35000000e+01, 1.50000000e+00],\n",
              "       [5.70000000e+01, 0.00000000e+00, 2.28000000e-01, 9.70000000e+00,\n",
              "        4.29000000e+00, 1.10000000e+01, 1.00000000e+00],\n",
              "       [7.80000000e+01, 0.00000000e+00, 2.30000000e-01, 4.00000000e+01,\n",
              "        6.23000000e+00, 1.40000000e+01, 1.40000000e+00],\n",
              "       [6.20000000e+01, 0.00000000e+00, 2.60000000e-01, 7.60000000e+00,\n",
              "        4.42000000e+00, 1.40000000e+01, 1.00000000e+00]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np_features = features_clear.values\n",
        "\n",
        "np_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Q0IYzDKpd5YY",
        "outputId": "6df04b0c-5718-47bf-ba32-d79f1483a098"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      12\n",
              "0    0.0\n",
              "1    0.0\n",
              "2    0.0\n",
              "3    0.0\n",
              "4    0.0\n",
              "..   ...\n",
              "104  1.0\n",
              "105  0.0\n",
              "106  0.0\n",
              "108  1.0\n",
              "109  1.0\n",
              "\n",
              "[74 rows x 1 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = dataset_clear.iloc[:, [12]]\n",
        "\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ1yAoME7aRY"
      },
      "source": [
        "Τέλος, εφαρμόζεται flatten για να προκύψει ο ακόλουθος πίνακας."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8eSNDe7eNQY",
        "outputId": "f9f9cc61-7320-40bc-bd2c-a4ffe58e0de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 1.])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np_labels = labels.values.flatten()\n",
        "\n",
        "print(np_labels.shape)\n",
        "np_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4n3i4Lh7hSu"
      },
      "source": [
        "Έτσι, συνοπτικά, τα δεδομένα θα είναι τα εξής:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ADJzVNAG3T",
        "outputId": "8d93cacd-961b-4037-f75e-708f160c314d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "classes: 2\n",
            "\n",
            " Value  Plithos  Frequency\n",
            "   0.0       50   0.675676\n",
            "   1.0       24   0.324324\n",
            "\n",
            "Larger class is 2.0833333333333335 times bigger than the smaller one\n",
            "\n",
            "Dataset: Not balanced\n"
          ]
        }
      ],
      "source": [
        "print('classes:', len(set(list(np_labels))))\n",
        "print(\"\")\n",
        "\n",
        "df = pd.Series(np_labels).value_counts().sort_index().reset_index()\n",
        "df.columns = ['Value', 'Plithos']\n",
        "df['Frequency'] = df['Plithos']/df['Plithos'].sum()\n",
        "print(df.to_string(index = False))\n",
        "print(\"\")\n",
        "\n",
        "ratio = df['Plithos'].max()/df['Plithos'].min()\n",
        "print(\"Larger class is\", ratio, \"times bigger than the smaller one\")\n",
        "print(\"\")\n",
        "\n",
        "if ratio < 1.5:\n",
        "    print('Dataset: Balanced')\n",
        "else:\n",
        "    print('Dataset: Not balanced')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGS-ynki8pS3"
      },
      "source": [
        "### Σχολιασμός\n",
        "\n",
        "Για το data set είναι μη ισορροπημένο αν μια οποιαδήποτε κλάση είναι 1.5 φορά πιο συχνή από κάποια άλλη.\n",
        "\n",
        "Το dataset είναι binary, καθώς υπάρχουν δύο κλάσεις. Αυτό εξυπηρετεί και τον υπολογισμό του f1-score για να μην χρειάζεται η παράμετρος macro στο f1_score, κάτι που χρησιμοποιείται σε multiclass datasets. Σημειώνεται όμως ότι έτσι θα είναι πιο σωστές οι συγκρίσεις αν και δεν σχετίζεται με τη βελτιστοποίηση."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEI-LlPethQ"
      },
      "source": [
        "## Προετοιμασία"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0DkQNOAB2hA"
      },
      "source": [
        "Αρχικά, γίνεται ο διαχωρισμός του συνόλου δεδομένων σε σύνολο εκπαίδευσης (train set) και σύνολο (test set) με 30% των δειγμάτων στο test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFxJpuCVean5",
        "outputId": "70ba4d8c-4bfc-47f6-c18d-52e4c061b9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(51, 7) (23, 7)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(np_features, np_labels, test_size=0.3)\n",
        "print(train.shape,test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xfva8ghB-3V"
      },
      "source": [
        "## Ταξινόμηση"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1LAbCSYCDX2"
      },
      "source": [
        "### Ταξινομητές\n",
        "\n",
        "Στο UCI εξετάζονται οι ταξινομητές:\n",
        "\n",
        ">dummy\n",
        "\n",
        ">Gaussian Naive Bayes (GNB)\n",
        "\n",
        ">KNeirestNeighbors (kNN)\n",
        "\n",
        ">Logistic Regression (LR)\n",
        "\n",
        "### Μετρικές\n",
        "\n",
        "Η βελτιστοποίηση και η παρουσίαση των αποτελεσμάτων γίνεται ξεχωριστά για δύο μετρικές:\n",
        "\n",
        ">ορθότητα (accuracy)\n",
        "\n",
        ">F1-score (macro σε προβλήματα multiclass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riNdHdEnCgEA"
      },
      "source": [
        "### Σχήμα διασταυρούμενης επικύρωσης\n",
        "\n",
        "Για όλα τα πειράματα θα χρησιμοποιείται 10-fold cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD4TdkbckDuq"
      },
      "source": [
        "### Επίδοση out-of-the-box\n",
        "\n",
        "Στην συνέχεια, φαίνεται η συμπεριφορά των ταξινομητών χωρίς καμία βελτιστοποίηση (out-of-the-box) και με όλες τις παραμέτρους σε default τιμές.\n",
        "Όλοι οι εκτιμητές εκπαιδεύονται με ένα απλό fit σε ολόκληρο το training set και υπολογίζεται η επίδοσή τους στο test set για τις δύο μετρικές. Τέλος, παρουσιάζεται συνοπτικά και συγκριτικά την επιδοσή τους:\n",
        "1. σε πίνακα markdown\n",
        "2. σε bar plot σύγκρισης\n",
        "\n",
        "και σχολιάζεται η επίδοσή τους."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfz0txJHkqB1"
      },
      "source": [
        "### **Dummy Classifier**\n",
        "\n",
        "Η κλάση DummyClassifier δέχεται μια παράμετρο που καθορίζει την τακτική της ταξινόμησης ως εξής:\n",
        "* “uniform”: προβλέπει τυχαία και ομοιόμορφα.\n",
        "* “constant”: προβλέπει πάντα μία κατηγορία που τη διαλέγει ο χρήστης.\n",
        "* “most_frequent”: προβλέπει πάντα την πιο συχνή κατηγορία στο training set.\n",
        "* “stratified”: κάνει προβλέψεις διατηρώντας την κατανομή των κλάσεων στο training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe_u8ET7kCJh"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dc_uniform =       DummyClassifier(strategy = \"uniform\")\n",
        "dc_constant_0 =    DummyClassifier(strategy = \"constant\", constant=0)\n",
        "dc_constant_1 =    DummyClassifier(strategy = \"constant\", constant=1)\n",
        "dc_most_frequent = DummyClassifier(strategy = \"most_frequent\")\n",
        "dc_stratified =    DummyClassifier(strategy = \"stratified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "849NnqpkMoox"
      },
      "source": [
        "Με τη μέθοδο fit εκπαιδεύεται ο ταξινομητής στο σύνολο εκπαίδευσης."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eChi7XgrxAAb"
      },
      "outputs": [],
      "source": [
        "model_uniform =       dc_uniform.fit(train, train_labels)\n",
        "model_constant_0 =    dc_constant_0.fit(train, train_labels)\n",
        "model_constant_1 =    dc_constant_1.fit(train, train_labels)\n",
        "model_most_frequent = dc_most_frequent.fit(train, train_labels)\n",
        "model_stratified =    dc_stratified.fit(train, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wjYp0nBM6x7"
      },
      "source": [
        "Με τη μέθοδο predict παράγονται προβλέψεις για τα δεδομένα ελέγχου."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztj7xmoixCq4",
        "outputId": "266f2f47-5492-4be7-8ca2-da5adf89aa54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "pred_uniform = dc_uniform.predict(test)\n",
        "print(pred_uniform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYWsBcPAM_L_",
        "outputId": "8a56e523-a9c6-4c07-ce3b-eb0034d132ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "pred_constant_0 = dc_constant_0.predict(test)\n",
        "print(pred_constant_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re0cCxrUM_Er",
        "outputId": "3195b826-2bc6-4339-86d7-f54adc45c372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "pred_constant_1 = dc_constant_1.predict(test)\n",
        "print(pred_constant_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfhI2b-3M--v",
        "outputId": "2f839a4d-5281-4ff0-a868-0f93d52aa8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "pred_most_frequent = dc_most_frequent.predict(test)\n",
        "print(pred_most_frequent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVtaOpEDM-3g",
        "outputId": "19ae4a7b-9091-48ce-a3b1-24f9aeaa1dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "pred_stratified = dc_stratified.predict(test)\n",
        "print(pred_stratified)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOTEI7XMiR4R"
      },
      "source": [
        "### Accuracy (Ορθότητα)\n",
        "\n",
        "Για την αξιολόγηση, το πιο απλό κριτήριο είναι η σύγκριση του ποσοστού ομοιότητας των πίνακων preds και test_labels. Το κριτήριο αυτό ονομάζεται ορθότητα (accuracy). Αν το κάναμε manually, για κάθε στοιχείο (δείγμα) των πινάκων που είναι όμοιο (0 και 0 ή 1 και 1) αυξάνουμε έναν μετρητή. Στην περίπτωση που είναι ανόμοια δεν τον αυξάνουμε. Διαιρούμε την τελική τιμή του μετρητή με το πλήθος των στοιχείων του πίνακα. Το προηγούμενο for loop μας το δίνει έτοιμο η συνάρτηση accuracy_score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHYfjD0VNrvN",
        "outputId": "4a435c2d-2b83-4f3b-9c6c-b3b93e50b75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform:\n",
            "0.6086956521739131\n",
            "0.34782608695652173\n",
            "\n",
            "Constant 0:\n",
            "0.6086956521739131\n",
            "0.6086956521739131\n",
            "\n",
            "Constant 1:\n",
            "0.391304347826087\n",
            "0.391304347826087\n",
            "\n",
            "Most Frequent:\n",
            "0.6086956521739131\n",
            "0.6086956521739131\n",
            "\n",
            "Stratified:\n",
            "0.5217391304347826\n",
            "0.5217391304347826\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Uniform:\")\n",
        "print(accuracy_score(test_labels, pred_uniform))\n",
        "print(dc_uniform.score(test, test_labels))\n",
        "print(\"\")\n",
        "print(\"Constant 0:\")\n",
        "print(accuracy_score(test_labels, pred_constant_0))\n",
        "print(dc_constant_0.score(test, test_labels))\n",
        "print(\"\")\n",
        "print(\"Constant 1:\")\n",
        "print(accuracy_score(test_labels, pred_constant_1))\n",
        "print(dc_constant_1.score(test, test_labels))\n",
        "print(\"\")\n",
        "print(\"Most Frequent:\")\n",
        "print(accuracy_score(test_labels, pred_most_frequent))\n",
        "print(dc_most_frequent.score(test, test_labels))\n",
        "print(\"\")\n",
        "print(\"Stratified:\")\n",
        "print(accuracy_score(test_labels, pred_stratified))\n",
        "print(dc_stratified.score(test, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKeSHH7lO3R5"
      },
      "source": [
        "### Σχολιασμός\n",
        "Παρατηρείται ότι αν τρέξουμε το πρoηγούμενο κελί διαδοχικές φορές, το δεύτερο accuracy αλλάζει γιατί καλούμε εκ νέου τον ταξινομητή να κάνει (τυχαίες) προβλέψεις. Επομένως, επιλέγεται η αποθήκευση της ορθότητας όλων των dummy classifiers σε ένα λεξικό και η αποτύπωση από την καλύτερη στη χειρότερη."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfggtFm2lUHp",
        "outputId": "a122f7fe-81af-484c-aa96-66d24247fa81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy on the Dummy Classifier on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "constant 0 0.6086956521739131\n",
            "most frequent label 0.6086956521739131\n",
            "stratified 0.6086956521739131\n",
            "uniform (random) 0.43478260869565216\n",
            "constant 1 0.391304347826087\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class_accuracy = {}\n",
        "class_accuracy['uniform (random)'] = dc_uniform.score(test, test_labels)\n",
        "\n",
        "model = dc_constant_0.fit(train, train_labels)\n",
        "class_accuracy['constant 0'] = dc_constant_0.score(test, test_labels)\n",
        "\n",
        "model = dc_constant_1.fit(train, train_labels)\n",
        "class_accuracy['constant 1'] = dc_constant_1.score(test, test_labels)\n",
        "\n",
        "model = dc_most_frequent.fit(train, train_labels)\n",
        "class_accuracy['most frequent label'] = dc_most_frequent.score(test, test_labels)\n",
        "\n",
        "model = dc_stratified.fit(train, train_labels)\n",
        "class_accuracy['stratified'] = dc_stratified.score(test, test_labels)\n",
        "\n",
        "print(\"Classification Accuracy on the Dummy Classifier on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "sorted_accuracy = [(k, class_accuracy[k]) for k in sorted(class_accuracy, key=class_accuracy.get, reverse=True)]\n",
        "for k, v in sorted_accuracy:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqbiK21SiXux"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycLlhMfxxKk2",
        "outputId": "75b528de-7662-4962-a82a-e990d0875c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification F1-Score on the Dummy Classifier on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "uniform (random) 0.5714285714285715\n",
            "constant 1 0.5625\n",
            "stratified 0.15384615384615383\n",
            "constant 0 0.0\n",
            "most frequent label 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class_f1 = {}\n",
        "class_f1['uniform (random)'] = f1_score(test_labels, pred_uniform)\n",
        "\n",
        "model = dc_constant_0.fit(train, train_labels)\n",
        "class_f1['constant 0'] = f1_score(test_labels, pred_constant_0)\n",
        "\n",
        "model = dc_constant_1.fit(train, train_labels)\n",
        "class_f1['constant 1'] = f1_score(test_labels, pred_constant_1)\n",
        "\n",
        "model = dc_most_frequent.fit(train, train_labels)\n",
        "class_f1['most frequent label'] = f1_score(test_labels, pred_most_frequent)\n",
        "\n",
        "model = dc_stratified.fit(train, train_labels)\n",
        "class_f1['stratified'] = f1_score(test_labels, pred_stratified)\n",
        "\n",
        "print(\"Classification F1-Score on the Dummy Classifier on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "sorted_f1_score = [(k, class_f1[k]) for k in sorted(class_f1, key=class_f1.get, reverse=True)]\n",
        "for k, v in sorted_f1_score:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETUXsbRURBJT"
      },
      "source": [
        "### **Gaussian Naive Bayes (GNB) Classifier**\n",
        "\n",
        "H βασική ιδέα λειτουργίας του ταξινομητή είναι:\n",
        "\n",
        "α) ο γνωστός νόμος του Bayes $$P(A\\mid B)={\\frac {P(B\\mid A)\\,P(A)}{P(B)}}$$\n",
        "\n",
        "β) η (naive) υπόθεση ότι τα χαρακτηριστικά είναι όλα ανεξάρτητα μεταξύ τους (δεν ισχύει γενικά, αλλά ο ταξινομητής είναι πρακτικά καλός σε πολλές περιπτώσεις). \n",
        "\n",
        "Παράδειγμα: θα βρέξει σήμερα? Naive Bayes: \"Θα το προβλέψω με βάση το παρελθόν θεωρώντας ότι τα χαρακτηριστικά θερμοκρασία, νεφοκάλυψη και ατμοσφαιρική πίεση είναι όλα ανεξάρτητα μεταξύ τους\".\n",
        "\n",
        "Με δεδομένα μια μεταβλητή κατηγορίας (κλάσης) $y$ και ένα εξαρτώμενο διάνυσμα χαρακτηριστικών $x_1$ μέχρι $x_n$, σύμφωνα με το θεώρημα του Bayes θα ισχύει \n",
        "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
        "Ισχύει ότι $P(x_1, \\dots, x_i, \\dots, x_n \\mid y) =  \\prod_{i=1}^{n} P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n)$ και κάνουμε την αφελή υπόθεση ότι το χαρακτηριστικό $x_i$ για κάθε $i$ εξαρτάται μόνο από την κλάση $y$ και όχι από οποιοδήποτε άλλο χαρακτηριστικό\n",
        "$$P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = P(x_i | y)$$\n",
        "αυτό οδηγεί στην απλοποίηση\n",
        "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
        "Με δεδομένη είσοδο, το $P(x_1, \\dots, x_n)$ είναι σταθερό. Συνεπώς μπορούμε να χρησιμοποιήσουμε τον ακόλουθο κανόνα ταξινόμησης $$P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
        "$$\\Downarrow$$\n",
        "$$\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
        "Το $P(y)$ είναι η υπόθεσή μας και ισούται με τη σχετική συχνότητα της κλάσης $y$ στο training set. To $P(x_i \\mid y)$ είναι η πιθανοφάνεια δηλαδή η πιθανότητα του δείγματος με δεδομένη την υπόθεσή μας και μπορεί επίσης να υπολογιστεί απλά από το training set. Οι διάφοροι Naive Bayes classifiers διαφοροποιούνται κυρίως από τις υποθέσεις που κάνουν ως προς την κατανομή $P(x_i \\mid y)$. Η κλάση $\\hat{y}$ που ανατίθεται σε ένα νέο δείγμα είναι αυτή που μεγιστοποιεί το δεξί μέλος της σχέσης.\n",
        "\n",
        "Θέλουμε να δοκιμάσουμε τον Naive Bayes στο Echocardiogram. Εδώ όμως έχουμε συνεχείς μεταβλητές. Όπως είπαμε θα πρέπει να κάνουμε μια υπόθεση για την κατανομή $P(x_i \\mid y)$. Θα θεωρήσουμε ότι η κατανομή κάθε χαρακτηριστικού ως προς κάθε κλάση ακολουθεί την κανονική κατανομή:\n",
        "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$\n",
        "Ο συγκεκριμένος ταξινομητής είναι ο Gaussian Naive Bayes. Πρακτικά, με τα δεδομένα του training set, για κάθε κλάση υπολογίζουμε τη μέση τιμή $\\mu_y$ και τη διακύμανση $\\sigma^2_y$ κάθε χαρακτηριστικού για τη συγκεκριμένη κλάση. \n",
        "Πρακτικά, όσο πιο κοντά στη μέση τιμή του (ως προς το σύνολο του train set)είναι ένα χαρακτηριστικό ενός δείγματος, τόσο πιο κοντά στη μοναδα θα είναι η πιθανοφάνια του χαρκτηριστικού και αντιθετοαντίστροφα."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHO9NUhKxQU8"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "# κάνουμε εκπαίδευση (fit) δηλαδή ουσιαστικά υπολογίζουμε μέση τιμή και διακύμανση για όλα τα χαρακτηριστικά και κλάσεις στο training set\n",
        "model = gnb.fit(train, train_labels)\n",
        "# η GaussianNB έχει builtin μέθοδο υπολογισμό accuracy. Αποθηκεύουμε την τιμή της στον πίνακά μας με τα αποτελέσματα από τα άλλα classifiers\n",
        "pred_gnb = gnb.predict(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ItQ9XbdierM"
      },
      "source": [
        "### Accuracy (Ορθότητα)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muEJQrXighL",
        "outputId": "2f7bdff8-8f38-45a6-edbf-387b3cea9a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy on the Gaussian Naive Bayes (GNB) Classifier on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "0.6956521739130435\n",
            "\n",
            "gnb 0.6956521739130435\n",
            "constant 0 0.6086956521739131\n",
            "most frequent label 0.6086956521739131\n",
            "stratified 0.6086956521739131\n",
            "uniform (random) 0.43478260869565216\n",
            "constant 1 0.391304347826087\n"
          ]
        }
      ],
      "source": [
        "class_accuracy['gnb'] = gnb.score(test, test_labels)\n",
        "print(\"Classification Accuracy on the Gaussian Naive Bayes (GNB) Classifier on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "print(gnb.score(test, test_labels))\n",
        "print(\"\")\n",
        "\n",
        "sorted_accuracy = [(k, class_accuracy[k]) for k in sorted(class_accuracy, key=class_accuracy.get, reverse=True)]\n",
        "for k, v in sorted_accuracy:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji5KtlnvikSL"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAKcb983imi9",
        "outputId": "bbd75107-5729-41b4-bd9e-33d052db1cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification F1-Score on the Gaussian Naive Bayes (GNB) Classifier on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "0.5333333333333333\n",
            "\n",
            "uniform (random) 0.5714285714285715\n",
            "constant 1 0.5625\n",
            "gnb 0.5333333333333333\n",
            "stratified 0.15384615384615383\n",
            "constant 0 0.0\n",
            "most frequent label 0.0\n"
          ]
        }
      ],
      "source": [
        "class_f1['gnb'] = f1_score(test_labels, pred_gnb)\n",
        "print(\"Classification F1-Score on the Gaussian Naive Bayes (GNB) Classifier on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "print(f1_score(test_labels, pred_gnb))\n",
        "print(\"\")\n",
        "\n",
        "sorted_f1_score = [(k, class_f1[k]) for k in sorted(class_f1, key=class_f1.get, reverse=True)]\n",
        "for k, v in sorted_f1_score:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RzHBxM1T5TC"
      },
      "source": [
        "## Θεωρία\n",
        "O Gaussian Naive Bayes είναι ένας παραμετρικός ταξινομητής. Οι παραμετρικοί ταξινομητές κάνουν κάποια υπόθεση για την κατανομή (των χαρακτηριστικών) των δεδομένων και την προσδιορίζουν μέσω παραμέτρων. Στην περίπτωση του Gaussian Naive Bayes, η υπόθεση είναι η κανονική κατανομή και οι παράμετροι είναι τα $μ$ και $σ^2$ των χαρακτηριστικών. Αντίθετα, οι μη-παραμετρικές μέθοδοι δεν κάνουν καμία υπόθεση για την κατανομή των δεδομένων. Προσοχή: και οι μη-παραμετρικοί ταξινομητές έχουν παραμέτρους (και πάρα πολλές σε ορισμένες περιπτώσεις, τα βάρη των νευρωνικών για παράδειγμα) που επηρ\n",
        "εάζουν τη λειτουργία τους αλλά δεν σχετίζονται με κάποια υπόθεση κατανομής για τα δεδομένα. \n",
        "\n",
        "Σε γενικές γραμμές οι παραμετρικοί ταξινομητές είναι απλούστεροι, ταχύτεροι στις φάσεις train/test και χρειάζονται λιγότερα δεδομένα εκπαίδευσης. Από την άλλη, έχουν γενικά μικρότερη χωρητικότητα (capacity), δηλαδή μπορούν να διαχωρίσουν τις κλάσεις σε προβλήματα σχετικά μικρότερων διαστάσεων ενώ η απαίτηση τα πραγματικά δεδομένα να ακολουθούν μια ακριβή κατανομή είναι πολύ ισχυρή και δεν επαληθεύεται πρακτικά. Αντιστρόφως, οι μη παραμετρικοί ταξινομητές είναι πιο αργοί στην εκπαίδευση, έχουν γενικά μεγαλύτερες απαιτήσεις χώρου/μνήμης και χρειάζονται περισσότερα δεδομένα αλλά έχουν μεγαλύτερη χωρητικότητα, μπορούν να μάθουν δυσκολότερα προβλήματα και να έχουν καλύτερη απόδοση σε μεγαλύτερα datasets. \n",
        "\n",
        "Οι μη παραμετρικοί ταξινομητές μπορούν να εμφανίσουν επίσης εντονότερα το πρόβλημα της υπερεκπαίδευσης (overfitting), δηλαδή να προσαρμοστούν υπερβολικά στα δεδομένα εκπαίδευσης και να μειωθεί η ικανότητα γενίκευσης (generalisation) τους σε νέα δείγματα. Γενικά στη φάση της εκπαίδευσης προσπαθούμε να επιτύχουμε μια καλή ισορροπία μεταξυ της απόκλισης (bias) και της διακύμανσης (variance) από τις πραγματικές τιμές.\n",
        "\n",
        "![Bias-Variance trade off](https://cdn-images-1.medium.com/proxy/1*e4Kn-_M_KN2bw-e6kevywA.png \"Bias-Variance trade off\")\n",
        "\n",
        "\n",
        "Ένα παράδειγμα μη-παραμετρικού ταξινομητή που θα εξετάσουμε είναι ο kNN (k-Nearest-Neighbours)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOxdiSmoUD4u"
      },
      "source": [
        "## **k-Neirest Neighbors (kNN) Classifier**\n",
        "O kNN είναι ένας μη παραμετρικός ταξινομητής βασισμένος σε παραδείγματα (instance-based). Η αρχή λειτουργίας του είναι πολύ απλή. Για ένα νέο δείγμα προς ταξινόμηση, πρώτα υπολογίζουμε τους k πλησιέστερους γείτονές του (στον ν-διάστατο χώρο των χαρακτηριστικών εισόδου) με βάση κάποια συνάρτηση απόστασης, συνήθως ευκλείδεια\n",
        "$$d(x, x') = \\sqrt{\\left(x_1 - x'_1 \\right)^2 + \\left(x_2 - x'_2 \\right)^2 + \\dotsc + \\left(x_n - x'_n \\right)^2}$$\n",
        "Η κλάση του νέου δείγματος θα είναι η κλάση της πλειοψηφίας των k γειτόνων (διαλέγουμε k περιττό γενικά), είτε απλά υπολογισμένη (άθροισμα) είτε (αντίστροφα) ζυγισμένη με βάση την απόσταση του κάθε γείτονα. \n",
        "\n",
        "Ο kNN δεν έχει πρακτικά φάση εκπαίδευσης. Ωστόσο, για να ταξινομήσουμε ένα νέο δείγμα στην φάση test,  πρέπει να συγκρίνουμε την απόστασή του με κάθε δείγμα του train set. Αυτό σημαίνει ότι για την ταξινόμηση είναι απαραίτητα όλα τα δείγματα εκπαίδευσης (εξού και η ονομασία \"instance-based\", ενώ στον Naive Bayes χρειαζόμαστε μόνο τις παραμέτρους $μ$ και $σ^2$). Αυτό σημαίνει ότι ο kNN είναι πιο απαιτητικός και σε χώρο (αποθήκευση όλων των δειγμάτων) και σε χρόνο (υπολογισμός όλων των αποστάσεων για κάθε νέο δείγμα).\n",
        "# Υπερπαράμετρος k\n",
        "Το k της γειτονιάς του kNN είναι μια υπερπαράμετρος του ταξινομητή. Μια άλλη υπερπαράμετρος για παράδειγμα είναι η συνάρτηση της απόστασης. Οι υπερπαράμετροι είναι επιλογές που γίνονται από τον σχεδιαστή του συστήματος και δεν μπορούμε να ξέρουμε τις βέλτιστες τιμές τους αν πρώτα δεν τις αξιολογήσουμε εμπειρικά σε δεδομένα.  Ένα άλλο παράδειγμα υπερπαραμέτρου είναι ο αριθμός των κρυφών νευρώνων σε ένα MLP. Στην περίπτωση του kNN το k ελέγχει το trade-off μεταξύ μεταξύ απόκλισης και διακύμνανσης.\n",
        "\n",
        "Έαν θέσουμε μικρό k, πχ k=1 παίρνουμε ένα ταξινομητή με υψηλή διακύμανση και χαμηλή απόκληση. Ο ταξινομητής τείνει να αγνοεί τη συνολική κατανομή και αποφασίζει μόνο από το κοντινότερο δείγμα. Στην περίπτωση k=1 το σύνορο απόφασης (decision boundary) περνά από τις μεσοκάθετους γειτονικών δειγμάτων διαφορετικής κλάσης. \n",
        "\n",
        "![kNN k=1](https://i.stack.imgur.com/UG81y.png \"kNN with k=1\")\n",
        "\n",
        "Αν διαλέξουμε μεγαλύτερο k, φτιάχνουμε ένα ταξινομητή με χαμηλότερη διακύμανση και υψηλότερη απόκλιση. Θα ταξινομίσει λάθος περισσότερα αποκλίνοντα δείγματα (outliers) αλλά θα σέβεται περισσότερο τη συνολική κατανομή.\n",
        "![kNN k=20](https://i.stack.imgur.com/FZITG.png \"kNN with k=20\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQjxrBbZVNmS"
      },
      "source": [
        "Επιλέγεται τυχαία τιμή για την υπερπαράμετρο k=5, ώστε να εκπαιδευτεί ο kNN classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoZyuS21inPw"
      },
      "outputs": [],
      "source": [
        "# Load KNN and organize data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn_model = knn.fit(train, train_labels)\n",
        "pred_knn = knn.predict(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1XJbM5xjMvS"
      },
      "source": [
        "### Accuracy (Ορθότητα)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2BcMLSOjOUC",
        "outputId": "c48e0107-854e-4400-ecd3-c7a2881fcfd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy on the k-Neirest Neighbors (kNN) Classifier on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "0.6956521739130435\n",
            "\n",
            "gnb 0.6956521739130435\n",
            "knn 0.6956521739130435\n",
            "constant 0 0.6086956521739131\n",
            "most frequent label 0.6086956521739131\n",
            "stratified 0.6086956521739131\n",
            "uniform (random) 0.43478260869565216\n",
            "constant 1 0.391304347826087\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Accuracy on the k-Neirest Neighbors (kNN) Classifier on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "class_accuracy['knn'] = knn.score(test, test_labels)\n",
        "print(accuracy_score(test_labels, pred_knn))\n",
        "print(\"\")\n",
        "\n",
        "sorted_accuracy = [(k, class_accuracy[k]) for k in sorted(class_accuracy, key=class_accuracy.get, reverse=True)]\n",
        "for k, v in sorted_accuracy:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yot0yyxGjPjv"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR-VCZv7jQ6Y",
        "outputId": "6e8ad2b2-56f3-461d-9ccb-cdf101a3e4a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification F1-Score on the k-Neirest Neighbors (kNN) Classifieron on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "0.46153846153846156\n",
            "\n",
            "uniform (random) 0.5714285714285715\n",
            "constant 1 0.5625\n",
            "gnb 0.5333333333333333\n",
            "knn 0.46153846153846156\n",
            "stratified 0.15384615384615383\n",
            "constant 0 0.0\n",
            "most frequent label 0.0\n"
          ]
        }
      ],
      "source": [
        "class_f1['knn'] = f1_score(test_labels, pred_knn)\n",
        "print(\"Classification F1-Score on the k-Neirest Neighbors (kNN) Classifieron on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "print(f1_score(test_labels, pred_knn))\n",
        "print(\"\")\n",
        "\n",
        "sorted_f1_score = [(k, class_f1[k]) for k in sorted(class_f1, key=class_f1.get, reverse=True)]\n",
        "for k, v in sorted_f1_score:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0FnZrXWX-h_"
      },
      "source": [
        "## **Λογιστική Παλινδρόμηση (Logistic Regression) (LR)**\n",
        "\n",
        "Παρόμοια με τον GNB και τον kNN, θα φτιάξουμε έναν ταξινομητή βασισμένο στη Λογιστική Παλινδόμηση from scratch, προτού χρησιμοποιήσουμε την έτοιμη συνάρτηση του scikit. Ξεκινάμε, όπως είναι αναμενόμενο για αυτό το παράδειγμα ταξινομητών, από την γραμμική παλινδόμηση.\n",
        "\n",
        "Η Λογιστική Παλινδρόμηση, παρά το όνομά της, είναι μέθοδος ταξινόμησης.\n",
        "\n",
        "![](https://rajputhimanshu.files.wordpress.com/2018/03/linear_vs_logistic_regression.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCVwonihZB1D"
      },
      "source": [
        "Γραμμική παλινδρόμηση\n",
        "\n",
        "Η συνάρτηση της ευθείας είναι $y=mx+b$, όπου $m$ η κλίση της ευθείας και $b$ το σημείο τομής του άξονα $Y$. Στην περίπτωση όπου τα δεδομένα έχουν μία διάσταση (scalar), η διαχωριστική επιφάνεια (*η υπόθεση*) του ταξινομητή είναι μια απλή ευθεία, σύμφωνα με τον προηγούμενο τύπο. Η εύρεση των *εμπειρικών* $\\hat{m}$ και $\\hat{b}$ γίνεται με τη μέθοδο των ελαχίστων τετραγώνων."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrOjs0yJZClq"
      },
      "source": [
        "Μέθοδος των Ελάχιστων Τετραγώνων\n",
        "Με τη Μέθοδο των Ελαχίστων Τετραγώνων προσπαθούμε να βρούμε μια ευθεία για την οποία η απόσταση κάθε σημείου $\\{x_i, y_i\\}$ είναι η ελάχιστη. Δήλαδή θέλουμε να βρούμε $$\\min_{b,m}Q(b,m) \\mbox{ όπου } Q(b,m) = \\sum_{i=1}^n\\hat{\\varepsilon}_i^{\\,2} = \\sum_{i=1}^n (y_i - b - m x_i)^2\\ $$\n",
        "\n",
        "Χρησιμοποιώντας απειροστικό λογισμό, την γεωμετρία του εσωτερικού γινόμενου ή απλά αναπτύσσοντας την συνάρτηση μπορεί να δειχθεί ότι οι τιμές $ b $ και $ m $ οι οποίες ελαχιστοποιούν την συνάρτηση $Q(b,m)$ είναι:\n",
        "$$ \\begin{align} \\hat{m} & = \\frac{ \\sum_{i=1}^{n} (x_{i}-\\bar{x})(y_{i}-\\bar{y}) }{ \\sum_{i=1}^{n} (x_{i}-\\bar{x})^2 }\n",
        "  = \\frac{ \\sum_{i=1}^{n}{x_{i}y_{i}} - \\frac1n \\sum_{i=1}^{n}{x_{i}}\\sum_{j=1}^{n}{y_{i}}}{ \\sum_{i=1}^{n}({x_{i}^2}) - \\frac1n (\\sum_{i=1}^{n}{x_{i}})^2 } =\\\\  &= \\frac{ \\overline{xy} - \\bar{x}\\bar{y} }{ \\overline{x^2} - \\bar{x}^2 } =   \\frac{ \\operatorname{Cov}[x,y] }{ \\operatorname{Var}[x] } = r_{xy} \\frac{s_y}{s_x},\\\\ \\hat{b}  & = \\bar{y} - \\hat{m}\\,\\bar{x}\\end{align}$$\n",
        "\n",
        "όπου $r_{xy} = \\frac{ Cov[x,y] }{s_xs_y}$ είναι η παράμετρος συσχέτισης μεταξύ $x$ και $y$, $s_x$ είναι η τυπική απόκλιση του $x$, και $s_y$ είναι αντίστοιχα η τυπική απόκλιση του $y$. Η οριζόντια γραμμή πάνω από μια μεταβλητή δηλώνει τον απλό μέσο όρο της μεταβλητής. Για παράδειγμα: $\\overline{xy} = \\tfrac{1}{n}\\textstyle\\sum_{i=1}^n x_iy_i.$ Τα \"b καπέλο\" $\\hat{b}$ και \"m καπέλο\" $\\hat{m}$ ονομάζονται εκτιμήτριες ελάχιστων τετραγώνων.\n",
        "Αντικαθιστώντας τις παραπάνω μαθηματικές εκφράσεις για τις παραμέτρους $\\hat{b}$ και $\\hat{m}$ στο $ y = \\hat{b} + \\hat{m} x, \\,$ πέρνουμε\n",
        "\n",
        "$\\frac{ y-\\bar{y}}{s_y} = r_{xy} \\frac{ x-\\bar{x}}{s_x}  $\n",
        "\n",
        "Αυτό δείχνει ότι το $r_{xy}$ έχει το ρόλο της γραμμής παλινδρόμησης για τα σημεία. Η συνάρτηση $ y = \\hat{b} + \\hat{m} x, $ λέγεται ευθεία ελαχίστων τετραγώνων ή ευθεία παλινδρόμησης. \n",
        "\n",
        "Στη μηχανική μάθηση η συνάρτηση αυτή λέγεται συνάρτηση υπόθεσης ή απλά *υπόθεση* και συμβολίζεται ως $ h_\\theta(x) = \\theta_0 + \\theta_1x$ (το $\\hat{b}$ και $\\hat{m}$ είναι οι παράμετροι $\\theta_0$ και $\\theta_1$ αντίστοιχα).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vZI6jfYZF1V"
      },
      "source": [
        "Πολλαπλή γραμμική παλινδρόμηση\n",
        "\n",
        "Σε περίπτωση που έχουμε δεδομένα που βρίσκονται εντός ενός πολυδιάστατου χώρου $m$, κάτι σύνηθες σε προβλήματα μηχανικής μάθησης, η ευθεία γενικεύεται (για *διανύσματα* εισόδου πλέον) σε $$y= β_1 ​ x_1 ​+...+β_mx_m ​ +b,$$ και μιλάμε πλέον για το πρόβλημα της πολλαπλής γραμμικής παλινδρόμησης όπου αναζητούμε τις τιμές $β$ (διάνυσμα) και b που ορίζουν το υπερεπίπεδο που έχει τη βέλτιστη προσαρμογή στα δεδομένα. \n",
        "\n",
        "Σημειώστε ότι το $y$ παραμένει ένας βαθμωτός αριθμος o οποίος στη γενική περίπτωση μπορεί να πάρει οποιαδήποτε τιμή."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gDpQJuFZI6h"
      },
      "source": [
        "Από τη γραμμική στη λογιστική παλινδρόμηση\n",
        "\n",
        "Σε περίπτωση που θα θέλαμε να μετατρέψουμε το πρόβλημα της παλινδρόμησης σε ένα πρόλβημα δυαδικής ταξινόμησης μια προσέγγιση θα ήταν να κοιτάξουμε το πεδίο τιμών της $y$ και να θέσουμε μια τιμή κατωφλιού $y_{thresh}$ για την οποία θα ισχύει $$\\begin{align} y_{i} &=1 \\text{, αν } y_i \\geq y_{thresh} \\text{ και }\\\\\n",
        "y_{i} &=0 \\text{ αλλιώς} \\end{align}\n",
        "$$\n",
        "Το πρόβλημα με αυτή την ευρετική μέθοδο είναι ότι ενώ πρακτικά πράγματι μετατρέπει το πρόβλημα παλινδρόμησης σε δυαδική ταξινόμηση, δεν υπάρχει κάποια θεωρητική βάση για να υποστηρίξει την ορθότητα της απόφασης μας. Αυτή θα υπήρχε, αν με κάποιο τρόπο μπορούσαμε να λάβουμε μια συνάρτηση πυκνότητας πιθανότητας για τα $P(y_i)$ έτσι ώστε αν $P(y_i)\\geq 0,5$ να έχουμε $y_{i} =1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbgN1wKbZNG4"
      },
      "source": [
        "Η λογιστική (σιγμοειδής) συνάρτηση\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png)\n",
        "\n",
        "Μια ιδιαίτερα βολική συνάρτηση για να λάβουμε τιμές στο διάσημα μεταξύ 0 και 1 είναι λογιστική σιγμοειδής συνάρτηση ή απλά λογιστική συνάρτηση:\n",
        "$$ f(x)={\\frac {1}{1+e^{-x}}} .$$ \n",
        "Ας την ορίσουμε:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFtEUp0kZTzO"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def sigmoid(x: float) -> float:\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "assert sigmoid(0) == 0.5 \n",
        "# Με την assert κάνουμε έλεγχο τιμών, μια καλή πρακτική \n",
        "# Αν δεν προκύπτει η ισότητα ο διερμηνευτής της Python θα πετάξει σφάλμα. \n",
        "# Αν είναι σωστή η τιμή η εκτέλεση θα συνεχιστεί χωρίς κάποια έξοδο."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grIqg-5dZPvn"
      },
      "source": [
        "Δημιουργία μιας συνάρτησης καταστολής (squashing function)\n",
        "\n",
        "Καταρχάς θα χρησιμοποιήσουμε ένα μικρό αλγεβρικό \"τρικ\" για να \"ξεφορτωθούμε\" τον όρο $b$ και να πάρουμε τη βολική μορφή του γινομένου. Θα προσθέσουμε στην αρχή του διανύσματος του $x$ έναν άσσο και στην αρχή του διανύσματος $β$ το $b$ ως εξής:\n",
        "$$\n",
        "\\vec{x}=\\left(\\begin{array}{c}\n",
        "1 \\\\\n",
        "x_{1} \\\\\n",
        "\\cdots \\\\\n",
        "x_{m}\n",
        "\\end{array}\\right) \\vec { β }=\\left(\\begin{array}{c}\n",
        "b \\\\\n",
        "\\beta_{1} \\\\\n",
        "\\cdots \\\\\n",
        "\\beta_{m}\n",
        "\\end{array}\\right)\n",
        "$$\n",
        "\n",
        "Συνεπώς τώρα μπορούμε να γράψουμε\n",
        "$$y= b + β_1 ​ x_1 ​+...+β_mx_m ​ +b= b +β_1 ​ x_1 ​+...+β_mx_m ​ =\\vec{x}\\cdot \\vec{β}$$\n",
        "όπου \"$\\cdot$\" είναι το εσωτερικό γινόμενο των δύο διανυσμάτων.\n",
        "\n",
        "Για παράδειγμα:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou280AY3Zvr5"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def dot(a: List[float], b: List[float]) -> float:\n",
        "    assert len(a) == len(b)\n",
        "    return sum([a_i * b_i for a_i, b_i in zip(a, b)])\n",
        "\n",
        "assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ironqSyMZzOJ"
      },
      "source": [
        "\n",
        "Μπορούμε τώρα να γράψουμε τώρα τη δική μας συνάρτηση καταστολής `squash` η οποία εφαρμόζει τη σιγμοειδή συνάρτηση πάνω στο εσωτερικό γινόμενο δύο διανυσμάτων ή αλλιώς που υπολογίζει το \n",
        "$$ y= \\sigma(β_1 ​ x_1 ​+...+β_mx_m ​ +b)$$ όπου $\\sigma$ η σιγμοειδής:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWJWhLWHZ0Sh"
      },
      "outputs": [],
      "source": [
        "def squash(beta: List[float], x: List[float]) -> float:\n",
        "    assert len(beta) == len(x)\n",
        "    # Calculate the dot product\n",
        "    dot_result: float = dot(beta, x)\n",
        "    # Use sigmoid to get a result between 0 and 1\n",
        "    return sigmoid(dot_result)\n",
        "\n",
        "assert squash([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNS0P6JZ3ST"
      },
      "source": [
        "Έχουμε λοιπόν μετατρέψει το πρόβλημα παλινδρόμησης σε πρόβλημα δυαδικής ταξινόμησης. Το ζητούμενό μας τώρα είναι το εξής: εφόσον μιλάμε για ταξινόμηση, δηλαδή επιβλεπόμενη μάθηση, για κάθε $x_i$ θα μας δίνονται οι επιθυμητές ετικέτες 0 και 1 $y_i$ και εμείς θα πρέπει να προσδιορίσουμε τις βέλτιστες τιμές του $β$ ή αλλοιώς να προσδιορίσουμε την υπόθεση μας με όρους μηχανικής μάθησης."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6mPbgpfZ6DJ"
      },
      "source": [
        "Συνάρτηση πυκνότητας πιθανότητας και συνάρτηση κόστους\n",
        "\n",
        "Για να μπορέσουμε να προχωρήσουμε θα πρέπει να ορίσουμε μια συνάρτηση υπό συνθήκης πιθανότητας που θα εκφράζει κατά πόσο \"πλησιάζουμε\" στη σωστή ετικέτα $y_i$ για κάθε δείγμα $x_i$ και τα βάρη μας $β$. Αυτή η συνάρτηση θα πρέπει αν έχει πιθανότητα $\\sigma(βx_i)$ για να είναι η ετικέτα \"1\" και $1-\\sigma(βx_i)$ για να είναι η ετικέτα \"0\". Μπορούμε να το γράψουμε σε μία εξίσωση ως εξής:\n",
        "$$\n",
        "P\\left(y_{i} \\mid \\beta x_{i}\\right)=\\sigma\\left(\\beta x_{i}\\right)^{y_{i}} \\times\\left(1-\\sigma\\left(\\beta x_{i}\\right)\\right)^{1-y_{i}}\n",
        "$$\n",
        "όπου ανάλογα αν $y_i=1$ ή $y_i=0$ μένει μόνο ο πρώτος ή ο δεύτερος όρος στη δεξιά πλευρά της εξίσωσης. Πρόκειται για τη συνάρτηση πιθανοφάνειας της υπόθεσής μας, η οποία επιθυμούμε να είναι η μέγιστη δυνατή.\n",
        "\n",
        "Εφόσον μας δίνονται τα $x_i$ και $y_i$ και πρέπει να βρούμε τα βέλτιστα βάρη $β$ θα χρειαστούμε μια συνάρτηση σφάλματος ή απώλειας (loss) $L(β|y_ix_i)$ προς ελαχιστοποίηση. \n",
        "Αρχικά, θα πάρουμε τον λογάριθμο της πιθανοφάνειας, κάτι που κανουμε συχνά για υπολογιστικούς λόγους. Ο λογάριθμος έχει την ίδια μονοτονία με την αρχικη συνάρτηση αλλά μας δίνει αθροίσματα τιμών αντί για γινόμενα. Στη συνέχεια, εφόσον στοχεύουμε σε ελαχιστοποίηση και οι λογάριθμοι είναι αρνητικοί, θα χρησιμοποιήσουμε την αρνητική συνάρτηση του λογάριθμου της log-πιθανοφάνειας. Τελικά προκύπτει:\n",
        "$$\n",
        "\\log L\\left(\\beta \\mid x_{i} y_{i}\\right)=-\\left(y_{i} \\log \\left(\\sigma\\left(\\beta x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\sigma\\left(\\beta x_{i}\\right)\\right)\\right)\n",
        "$$\n",
        "που είναι η συνάρτηση λογαριθμικού σφάλματος ή απώλειας (Log Loss / Log Likelihood) προς ελαχιστοποίηση. Την ορίζουμε:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ThT1kpFaAif"
      },
      "outputs": [],
      "source": [
        "def neg_log_likelihood(y: float, y_pred: float) -> float:\n",
        "    return -((y * math.log(y_pred)) + ((1 - y) * math.log(1 - y_pred)))\n",
        "\n",
        "assert 2.30 < neg_log_likelihood(1, 0.1) < 2.31\n",
        "assert 2.30 < neg_log_likelihood(0, 0.9) < 2.31\n",
        "assert 0.10 < neg_log_likelihood(1, 0.9) < 0.11\n",
        "assert 0.10 < neg_log_likelihood(0, 0.1) < 0.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibC3PfLVaD0n"
      },
      "source": [
        "Συνάρτηση κόστους\n",
        "Η συνάρτηση κόστους (cost function) είναι απλά το άθροισμα του σφάλματος για όλο το dataset: \n",
        "$$\n",
        "\\text { Cost }=-\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i} \\log \\left(\\sigma\\left(\\beta x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\sigma\\left(\\beta x_{i}\\right)\\right)\\right)\n",
        "$$\n",
        "Την ορίζουμε:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1NlmM4VaKXZ"
      },
      "outputs": [],
      "source": [
        "def error(ys: List[float], ys_pred: List[float]) -> float:\n",
        "    assert len(ys) == len(ys_pred)\n",
        "    num_items: int = len(ys)\n",
        "    sum_nll: float = sum([neg_log_likelihood(y, y_pred) for y, y_pred in zip(ys, ys_pred)])\n",
        "    return (1 / num_items) * sum_nll\n",
        "\n",
        "assert 2.30 < error([1], [0.1]) < 2.31\n",
        "assert 2.30 < error([0], [0.9]) < 2.31\n",
        "assert 0.10 < error([1], [0.9]) < 0.11\n",
        "assert 0.10 < error([0], [0.1]) < 0.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcGfW-HiaLlV"
      },
      "source": [
        "Οπότε, για το συγκεκριμένο data set, θα ισχύει:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQyET0VNjX24"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logisticRegr = LogisticRegression()\n",
        "logistic_model = logisticRegr.fit(train, train_labels)\n",
        "pred_lr = logisticRegr.predict(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnez1YdUjg_K"
      },
      "source": [
        "### Accuracy (Ορθότητα)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zxMx22yjiH_",
        "outputId": "238a543f-827f-4242-f2f3-358829b0cb0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy on the Logistic Regression (LR) on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "0.7391304347826086\n",
            "\n",
            "lr 0.7391304347826086\n",
            "gnb 0.6956521739130435\n",
            "knn 0.6956521739130435\n",
            "constant 0 0.6086956521739131\n",
            "most frequent label 0.6086956521739131\n",
            "stratified 0.6086956521739131\n",
            "uniform (random) 0.43478260869565216\n",
            "constant 1 0.391304347826087\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Accuracy on the Logistic Regression (LR) on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "class_accuracy['lr'] = accuracy_score(test_labels, pred_lr)\n",
        "print(accuracy_score(test_labels, pred_lr))\n",
        "print(\"\")\n",
        "\n",
        "sorted_accuracy = [(k, class_accuracy[k]) for k in sorted(class_accuracy, key=class_accuracy.get, reverse=True)]\n",
        "for k, v in sorted_accuracy:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUnyiyTMjlqY"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oDM-JsEjmyt",
        "outputId": "14e6dd2d-3a17-4542-f114-1507c09c778d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification F1-Score on the Logistic Regression (LR) on the Echocardiogram Dataset (30% test set)\n",
            "\n",
            "0.5714285714285714\n",
            "\n",
            "uniform (random) 0.5714285714285715\n",
            "lr 0.5714285714285714\n",
            "constant 1 0.5625\n",
            "gnb 0.5333333333333333\n",
            "knn 0.46153846153846156\n",
            "stratified 0.15384615384615383\n",
            "constant 0 0.0\n",
            "most frequent label 0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification F1-Score on the Logistic Regression (LR) on the Echocardiogram Dataset (30% test set)\\n\")\n",
        "class_f1['lr'] = f1_score(test_labels, pred_lr)\n",
        "print(f1_score(test_labels, pred_lr))\n",
        "print(\"\")\n",
        "\n",
        "sorted_f1_score = [(k, class_f1[k]) for k in sorted(class_f1, key=class_f1.get, reverse=True)]\n",
        "for k, v in sorted_f1_score:\n",
        "  print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynUiDZCcjtPL"
      },
      "source": [
        "## Παρουσίαση & Σύγκριση Επίδοσης των Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzCrxgSeaoWE"
      },
      "source": [
        "### Σύγκριση Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "EULYBbqojuFM",
        "outputId": "810ed7e9-8586-4876-c986-68a9e0c66b7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniform (random)</th>\n",
              "      <th>constant 0</th>\n",
              "      <th>constant 1</th>\n",
              "      <th>most frequent label</th>\n",
              "      <th>stratified</th>\n",
              "      <th>gnb</th>\n",
              "      <th>knn</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.73913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          uniform (random)  constant 0  constant 1  ...       gnb       knn       lr\n",
              "Accuracy          0.434783    0.608696    0.391304  ...  0.695652  0.695652  0.73913\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(data=class_accuracy, index =['Accuracy'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wXyHsx7arqh"
      },
      "source": [
        "### Σύγκριση F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "J5F7wMG2kMYj",
        "outputId": "ee38ccbb-b600-4d9e-b37a-ec32f5291867"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniform (random)</th>\n",
              "      <th>constant 0</th>\n",
              "      <th>constant 1</th>\n",
              "      <th>most frequent label</th>\n",
              "      <th>stratified</th>\n",
              "      <th>gnb</th>\n",
              "      <th>knn</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>F1-Score</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          uniform (random)  constant 0  ...       knn        lr\n",
              "F1-Score          0.571429         0.0  ...  0.461538  0.571429\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.DataFrame(data=class_f1, index =['F1-Score'])\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmoqRCc3aypA"
      },
      "source": [
        "Ακολούθως, παρουσιάζονται σε διάγραμμα οι Επιδόσεις Ορθότητας των Classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "5NVbkGTAkM7l",
        "outputId": "fb37e2c5-dca7-4de4-a1ac-d6838fd3a7ee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame({'accuracy': class_accuracy.keys(), 'classifiers': class_accuracy.values()}, index =  class_accuracy.keys())\n",
        "ax = df.plot.bar(rot=0, figsize=(12, 8), color='green', title='Accuracy of the above Classifiers')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9zXCvF2CwDI"
      },
      "source": [
        "### Σχολιασμός\n",
        "\n",
        "Πιθανώς οι γραφικές να διαφέρουν σε περίπτωση που εκτελεστούν ξανά τα cells λόγω της τυχαιότητας. Εν προκειμένω,\n",
        "- Ο Dummy Classifier του constant 0 εμφανίζεται πιο συχνά όπως και το most frequent. Έτσι, για τα δείγματα της κλάσης 0 επιτυγχάνονται καλύτερα αποτελέσματα της τάξης του 60%. Το uniform είναι περίπου 45% ενώ το stratified είναι 60%. Ο stratified δηλαδή, είναι πιο \"έξυπνος\" αφού μελετά την κατανομή των ετικετών στο training set και μετά προβλέπει με βάση το ποσοστό που πήρε για το κάθε label. Όμως, παρατηρείται ότι δεν μαθαίνει.\n",
        "- Ανάμεσα στον Gaussian Classifier και στον kNN Classifier, φαίνεται να έχουν εξίσου καλά αποτελέσματα αν και στον GNB το κάθε χαρακτηριστικό είναι ανεξάρτητο ενώ στον kNN, επειδή χρειάζονται όλα τα δείγματα εκπαίδευσης, είναι πιο απαιτητικός.\n",
        "- Τέλος, ο Logistic Regression ταξινομητής φαίνεται να είναι ο καλύτερος από όλους."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "WJJUxRzMkO-x",
        "outputId": "62a38d32-e015-40bb-a2b5-2c6068bb6acf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df2 = pd.DataFrame({'f1-score': class_f1.keys(), 'classifiers': class_f1.values()}, index =  class_f1.keys())\n",
        "ax2 = df2.plot.bar(rot=0, figsize=(12, 8), color='green', title='F1-Score of the above Classifiers')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0Fl76YtbbOl"
      },
      "source": [
        "### Σχολιασμός\n",
        "\n",
        "Πιθανώς οι γραφικές να διαφέρουν σε περίπτωση που εκτελεστούν ξανά τα cells λόγω της τυχαιότητας. Εν προκειμένω,\n",
        "- Ο Dummy Classifier του constant 1, εμφανίζεται περίπου στο 55% καθώς constant 0 και το most frequent απουσιάζουν. Το uniform είναι κι αυτό στο 55% και το stratified είναι περίπου στο 15%. Ο stratified δεν είναι πιο \"έξυπνος\".\n",
        "- Ανάμεσα στον Gaussian Classifier και στον kNN Classifier, ο GNB είναι αρκετά καλύτερος εδώ.\n",
        "- Τέλος, ο Logistic Regression ταξινομητής φαίνεται να είναι καλύτερος σε επίδοση από όλους και πάλι."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zHkUvnnetvr"
      },
      "source": [
        "## **Βελτιστοποίηση**\n",
        "\n",
        "Για όλους τους ταξινομητές βελτιστοποιήστε την επίδοσή τους μέσω των διαδικασιών\n",
        "- προεπεξεργασίας\n",
        "- ορισμού pipelines\n",
        "- εύρεσης βέλτιστων υπερμαραμέτρων με αναζήτηση πλέγματος με διασταυρούμενη επικύρωση\n",
        "\n",
        "Για το καλύτερο μοντέλο κάθε ταξινομητή, εκπαιδεύστε το στο σύνολο του train set και εκτιμήστε την επίδοσή του στο test set.Επιπρόσθετα, για τα βέλτιστα μοντέλα, καταγράψτε τους χρόνους train και test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE8_ylmCoiHU"
      },
      "source": [
        "### Προεπεξεργασία\n",
        "\n",
        "Στο παρόν data set υπάρχουν missing values οπότε απαιτείται η ανάλογη διαχείρισή τους. Αυτό το βήμα δεν είναι απαραίτητο βέβαια διότι στην συνέχεια θα χρησιμοποιήθούν έτοιμες συναρτήσεις για την βελτιστοποίηση."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CueWCmmso3Fa"
      },
      "source": [
        "Παρατηρήθηκε ότι για threshold >= 0.05 απορρίπονται λίγα χαρακτηριστικά οπότε επιλέχθηκε threshold = 0.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHY5K1N-qbtP",
        "outputId": "baa62a39-60cd-4b5f-987c-20fc0ed10278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: (51, 7)\n",
            "Reduced train set: (51, 4)\n",
            "Test set: (23, 7)\n",
            "Reduced test set: (23, 4)\n"
          ]
        }
      ],
      "source": [
        "selector = VarianceThreshold(threshold = 0.2) # initialization selector\n",
        "train_reduced = selector.fit_transform(train) # fit\n",
        "mask = selector.get_support() # mask selector to keep characteristics or not\n",
        "test_reduced = test[:, mask]\n",
        "\n",
        "print(\"Train set:\", train.shape)\n",
        "print(\"Reduced train set:\", train_reduced.shape)\n",
        "print(\"Test set:\", test.shape)\n",
        "print(\"Reduced test set:\", test_reduced.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbQWBnB_qZnB"
      },
      "source": [
        "### Κανονικοποίηση\n",
        "\n",
        "Εφαρμόζεται κανονικοποίηση με standardization αφού threshold > 0 στο VarianceThreshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "338kOOrxqkUD"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(train_reduced)\n",
        "train_scaled = scaler.transform(train_reduced)\n",
        "test_scaled = scaler.transform(test_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X459b58Rq69t"
      },
      "source": [
        "### Εξισορρόποηση data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAbnUjKxrDVf",
        "outputId": "55632b9e-e974-4774-b857-894570e230a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " index   0\n",
            "   0.0  36\n",
            "   1.0  15\n",
            "Shape of scaled Train set (51, 4)\n",
            "Shape of Train labels:  (51,)\n",
            "\n",
            " index   0\n",
            "   0.0  36\n",
            "   1.0  36\n",
            "Shape of re-sampled Train set (72, 4)\n",
            "Shape of re-sampled Train labels (72,)\n"
          ]
        }
      ],
      "source": [
        "raovs = RandomOverSampler() # initialization\n",
        "\n",
        "df = pd.Series(train_labels).value_counts().sort_index().reset_index()\n",
        "print(df.to_string(index=False))\n",
        "print(\"Shape of scaled Train set\", train_scaled.shape)\n",
        "print(\"Shape of Train labels: \", train_labels.shape)\n",
        "print(\"\")\n",
        "\n",
        "train_resampled, train_labels_resampled = raovs.fit_resample(train_scaled,train_labels)\n",
        "\n",
        "df = pd.Series(train_labels_resampled).value_counts().sort_index().reset_index()\n",
        "print(df.to_string(index=False))\n",
        "print(\"Shape of re-sampled Train set\", train_resampled.shape)\n",
        "print(\"Shape of re-sampled Train labels\", train_labels_resampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRTEpLtjOEOt"
      },
      "source": [
        "Ακολούθως, ορίζεται η PCA και ο τελικός αριθμός features και εφαρμόζεται εκπαίδευση με τον ίδιο Μ/Σ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1iZ6MDKFqVO"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9eJZ6ehemgf",
        "outputId": "06fcdb6b-860c-4a66-e1c0-3c99ed9b83b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of re-sampled Train set:  (72, 4)\n",
            "Shape of PCA Train set:  (72, 2)\n",
            "Shape of scaled Test set:  (23, 4)\n",
            "Shape of PCA Test set:  (23, 2)\n"
          ]
        }
      ],
      "source": [
        "n = 2\n",
        "pca = PCA(n_components=n)\n",
        "trainPCA = pca.fit_transform(train_resampled)\n",
        "testPCA = pca.transform(test_scaled)\n",
        "\n",
        "print(\"Shape of re-sampled Train set: \", train_resampled.shape)\n",
        "print(\"Shape of PCA Train set: \", trainPCA.shape)\n",
        "print(\"Shape of scaled Test set: \", test_scaled.shape)\n",
        "print(\"Shape of PCA Test set: \", testPCA.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTARV-ueNuDN"
      },
      "source": [
        "## **Hyperparameter tuning και Βέλτιστες Αρχιτεκτονικές**\n",
        "\n",
        "Ένα εκπαιδευμένο μοντέλο εκτιμητή (ταξινομητή) αποτελείται:\n",
        "- απο την αρχιτεκτονική του (συνδυασμός μετασχηματιστών) και από την επιλογή του τελικού εκτιμητή (pipeline)\n",
        "- από τις βέλτιστες τιμές των υπερ-παραμέτρων όλων των προηγουμένων που προκύπτουν από cross-validation\n",
        "\n",
        "Σημειώνεται ότι σε κάθε πείραμα θα χρησιμοποιήσουμε 10-fold cross-validation.\n",
        "Η μεθοδολογία που ακολουθήθηκε για την εύρεση της βέλτιστης αρχιτεκτονικής κάθε ταξινομητή είναι η \"bottom-up\". Αυτό σημαίνει ότι αρχικά υπήρχε μόνο ένας estimator και εν συνεχεία, θα προστέθηκαν μετασχηματιστές. Έπειτα, έγιναν δοκιμές σε διάφορα pipelines και με την χρήση predictions υπολογίστηκε το Accuracy και το F1-Score ώστε να βρεθεί ο βέλτιστος συνδυασμός. Μετά, με την GridSearchCV έγιναν δοκιμές για την βελτίωση ων υπερ-παραμέτρων. Επιπλέον, αν οι τιμές βρίσκονταν στα άκρα του διαστήματος αναζήτησης τότε προστέθηκαν τιμές ώστε η παράμετρος που προέκυπτε να βρίσκεται περίπου στο κέντρο του διαστήματος, ενώ αν η παράμετρος βρισκόταν στο κέντρο του διαστήματος της αναζήτησης τότε απορρίφθηκαν κάποιες από τις ακραίες τιμές και προστέθηκαν τιμές γύρω από εκείνη που προκρίθηκε προηγουμένως ως βέλτιστη και σε κάθε περίπτωση θα επαναλαμβάνεται το grid search, μέχρι να παρατηρηθεί κάποια σταθεροποίηση.  Επομένως, το καλύτερο μοντέλο κάθε ταξινομητή εκπαιδεύεται στο σύνολο του train set και υπολογίζεται η επίδοσή του στο test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoIg3gJdSkri",
        "outputId": "23e2ca6c-e924-4d22-f772-08a6afffc133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train variance:  [7.47999388e+01 1.32256824e-01 1.22284980e-02 4.47175546e+01\n",
            " 4.61539821e-01 2.35343505e+01 1.95049384e-01]\n",
            "\n",
            "74.79993880278951\n"
          ]
        }
      ],
      "source": [
        "selector = VarianceThreshold()\n",
        "scaler = StandardScaler()\n",
        "raovs = RandomOverSampler()\n",
        "pca = PCA()\n",
        "\n",
        "train_variance = train.var(axis=0)\n",
        "print(\"train variance: \", train_variance)\n",
        "print(\"\")\n",
        "print(np.max(train_variance))\n",
        "\n",
        "# dictionaries\n",
        "time_train_f1 = {}\n",
        "time_test_f1 = {}\n",
        "time_train_acc = {}\n",
        "time_test_acc = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfC7faF2TW_o"
      },
      "source": [
        "### **Dummy Classifier**\n",
        "\n",
        "Θεωρήθηκε ότι ο Dummy Classifier δεν μαθαίνει οπότε η περαιτέρω επεξεργασία του κρίνεται άνευ σημασίας αφού δεν σχετίζεται με τα χαρακτηριστικά των δειγμάτων του και επομένως δεν μπορεί να βελτιστοποιηθεί."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MskoeP5HUVGR"
      },
      "source": [
        "### **Gaussian Naive Bayes (GNB) Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5MT-6__TWUk"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoHGpbpdU7RV"
      },
      "source": [
        "Η ακόλουθη συνάρτηση υπολογίζει το Accuracy & F1-score των pipelines με 10-fold-cross-validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv8S2TcAdLGi"
      },
      "outputs": [],
      "source": [
        "def estim(pipe):\n",
        "  pipe.fit(train, train_labels)\n",
        "  \n",
        "  score_acc = cross_val_score(pipe, train, train_labels, cv=10, scoring='accuracy')\n",
        "  score_f1 = cross_val_score(pipe, train, train_labels, cv=10, scoring='f1')\n",
        "\n",
        "  print(\"accuracy\",score_acc.mean())\n",
        "  print(\"f1-score:\", score_f1.mean())\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UZIDPanVZa6"
      },
      "outputs": [],
      "source": [
        "gnb = GaussianNB()\n",
        "pipe_gnb = []\n",
        "\n",
        "pipe_gnb.append(Pipeline(steps=[('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('pca', pca),('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('sampler', raovs),('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('scaler', scaler), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('selector', selector), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('sampler', raovs),('pca', pca), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('scaler', scaler),('pca', pca), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('scaler', scaler),('sampler', raovs), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('selector', selector),('scaler', scaler), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('scaler', scaler),('sampler', raovs),('pca', pca), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('pca', pca), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('sampler', raovs), ('gnb', gnb)],memory = 'tmp'))\n",
        "pipe_gnb.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('sampler', raovs),('pca', pca), ('gnb', gnb)],memory = 'tmp'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI9PhaLxg0kJ"
      },
      "source": [
        "Μετά από δοκιμές, παρατηρήθηκε ότι το καλύτερο f1-score και accuracy προκύπτει με το pipeline 8. Όμως, προτιμάται η PCA αρχιτεκτονική 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IMKRjXXlqCj",
        "outputId": "4163d521-a387-4add-9757-7d113b33b145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'sampler', 'pca', 'gnb', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'sampler__random_state', 'sampler__sampling_strategy', 'sampler__shrinkage', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'gnb__priors', 'gnb__var_smoothing'])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipe_gnb[9].get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7gTxe4uhoS_"
      },
      "source": [
        "### Accuracy (Ορθότητα)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VapQHjc2mYyu"
      },
      "outputs": [],
      "source": [
        "scalers = [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()]\n",
        "n_components = list(np.arange(4,30,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzeyso9PMWS7",
        "outputId": "d88c2247-99cc-439e-d8dd-3347fc22062e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score  0.78\n",
            "\n",
            "Best estimator  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('pca', PCA(n_components=4)), ('gnb', GaussianNB())])\n"
          ]
        }
      ],
      "source": [
        "# GridSearch & f1-score\n",
        "estimator = GridSearchCV(pipe_gnb[10], dict(scaler = scalers,pca__n_components = n_components), cv=10, scoring='accuracy', n_jobs=-1)\n",
        "estimator.fit(train, train_labels)\n",
        "print(\"Best Score \", estimator.best_score_)\n",
        "print(\"\")\n",
        "print(\"Best estimator \", estimator.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0JytdEbMb5o",
        "outputId": "88612a39-83d6-4d78-f3a1-ca3dfe0824f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNB Classifier Best Parameters: {'pca__n_components': 4, 'scaler': StandardScaler()} \n",
            "\n",
            "Accuracy: 0.7391304347826086\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "gnb_best = estimator.best_estimator_\n",
        "print(\"GNB Classifier Best Parameters:\", estimator.best_params_, \"\\n\")\n",
        "# accuracy\n",
        "gnb_best.fit(train, train_labels)\n",
        "preds_gnb_acc = gnb_best.predict(test)\n",
        "print(\"Accuracy:\", accuracy_score(test_labels, preds_gnb_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx1nRbBQmecW"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8YfASF0hnYU"
      },
      "outputs": [],
      "source": [
        "scalers = [StandardScaler(), MinMaxScaler(),Normalizer(), MaxAbsScaler()]\n",
        "n_components = list(np.arange(4,30,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-w4dIAwNR8r",
        "outputId": "b81f027f-d7b2-488d-bc7d-40e8605ce420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score  0.5800000000000001\n",
            "Best estimator  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', MinMaxScaler()),\n",
            "                ('pca', PCA(n_components=4)), ('gnb', GaussianNB())])\n"
          ]
        }
      ],
      "source": [
        "# GridSearch & f1-score\n",
        "estimator = GridSearchCV(pipe_gnb[10], dict(scaler = scalers,pca__n_components = n_components), cv=10, scoring='f1', n_jobs=-1)\n",
        "estimator.fit(train, train_labels)\n",
        "print(\"Best Score \",estimator.best_score_)\n",
        "print(\"Best estimator \", estimator.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQFE5jUVNW74",
        "outputId": "b6096d2d-d30f-486b-b6d6-85f620d73a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNB Classifier Best Parameters: {'pca__n_components': 4, 'scaler': MinMaxScaler()} \n",
            "\n",
            "F1-Score: 0.5555555555555556\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "gnb_best = estimator.best_estimator_\n",
        "print(\"GNB Classifier Best Parameters:\", estimator.best_params_, \"\\n\")\n",
        "# f1-score\n",
        "gnb_best.fit(train, train_labels)\n",
        "preds_gnb_f1 = gnb_best.predict(test)\n",
        "print(\"F1-Score:\", f1_score(test_labels,preds_gnb_f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veHnDVS0mu9o"
      },
      "source": [
        "### Σχολιασμός:\n",
        "\n",
        "Για τον GNB, παρατηρείται ότι accuracy είναι ελαφρώς καλύτερο. Επιπλέον ο MaxAbsScaler() scaler φαίνεται να είναι η καλύτερη επιλογή στο συγκεκριμένο πείραμα.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pj4Ns7am59e"
      },
      "source": [
        "## **k-Neirest Neighbors (kNN) Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qthzq1amyJy"
      },
      "outputs": [],
      "source": [
        "from sklearn import neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWuler1NnJE5"
      },
      "outputs": [],
      "source": [
        "clf = neighbors.KNeighborsClassifier(n_jobs=-1) \n",
        "pipe_knn = []\n",
        "\n",
        "pipe_knn.append(Pipeline(steps=[ ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('pca', pca),('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('sampler', raovs),('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('scaler', scaler), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('selector', selector), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('sampler', raovs),('pca', pca), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('scaler', scaler),('sampler', raovs), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('selector', selector),('sampler', raovs), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('selector', selector),('scaler', scaler), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('scaler', scaler),('sampler', raovs),('pca', pca), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('pca', pca), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('sampler', raovs), ('knn', clf)],memory = 'tmp'))\n",
        "pipe_knn.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('sampler', raovs),('pca', pca), ('knn', clf)],memory = 'tmp'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrWRX3sZnQdq"
      },
      "source": [
        "Μετά από δοκιμές, παρατηρήθηκε ότι το καλύτερο f1-score και accuracy προκύπτει με το pipeline 11."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRdVnutencKq",
        "outputId": "f81235ee-b2ee-4756-cb13-cea65ec2330c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'selector', 'scaler', 'sampler', 'knn', 'selector__threshold', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'sampler__random_state', 'sampler__sampling_strategy', 'sampler__shrinkage', 'knn__algorithm', 'knn__leaf_size', 'knn__metric', 'knn__metric_params', 'knn__n_jobs', 'knn__n_neighbors', 'knn__p', 'knn__weights'])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipe_knn[11].get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbI93WOenaEd"
      },
      "source": [
        "### Accuracy (Ορθότητα)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7pTO1xqnjxl"
      },
      "outputs": [],
      "source": [
        "scalers = [StandardScaler(), MinMaxScaler(),Normalizer(), MaxAbsScaler()]\n",
        "n_components = [1,2,3,4,5,6,7,8]\n",
        "n_neighbors = list(np.arange(4,20,5))\n",
        "distance = ['euclidean','manhattan','chebyshev']\n",
        "vthreshold = [0.01, 0.1, 1, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w70tWm5VPvxG",
        "outputId": "c6e16ca9-abc8-4bb0-ab2c-5132755f7d7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score  0.8400000000000001\n",
            "\n",
            "Best estimator  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold(threshold=1)),\n",
            "                ('scaler', MinMaxScaler()), ('sampler', RandomOverSampler()),\n",
            "                ('knn',\n",
            "                 KNeighborsClassifier(metric='manhattan', n_jobs=-1,\n",
            "                                      n_neighbors=14))])\n"
          ]
        }
      ],
      "source": [
        "# GridSearch & f1-score\n",
        "estimator = GridSearchCV(pipe_knn[11], dict(selector__threshold=vthreshold,scaler = scalers,knn__metric = ['manhattan'],knn__n_neighbors = n_neighbors), cv=10, scoring='accuracy', n_jobs=-1)\n",
        "estimator.fit(train, train_labels)\n",
        "print(\"Best Score \",estimator.best_score_)\n",
        "print(\"\")\n",
        "print(\"Best estimator \", estimator.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfC4oUGnQJFm",
        "outputId": "a51f811f-fb48-4275-aa09-d714ed004578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kNN Classifier Best Parameters: {'knn__metric': 'manhattan', 'knn__n_neighbors': 14, 'scaler': MinMaxScaler(), 'selector__threshold': 1} \n",
            "\n",
            "Accuracy: 0.7391304347826086\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "knn_best = estimator.best_estimator_\n",
        "print(\"kNN Classifier Best Parameters:\", estimator.best_params_, \"\\n\")\n",
        "# accuracy\n",
        "knn_best.fit(train,train_labels)\n",
        "preds_knn_acc = knn_best.predict(test)\n",
        "print(\"Accuracy:\", accuracy_score(test_labels, preds_knn_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T53KDVuMn0pY"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVxvqh4Qn0Cb"
      },
      "outputs": [],
      "source": [
        "scalers = [StandardScaler(), MinMaxScaler(),Normalizer(), MaxAbsScaler()]\n",
        "n_components = [8,10,12,14,16,18]\n",
        "n_neighbors = list(np.arange(4,20,5))\n",
        "distance = ['euclidean','manhattan','chebyshev']\n",
        "vthreshold = [0.01, 0.1, 1, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kinOS9t4Qwv_",
        "outputId": "1f2c90ae-0e0e-45ad-8dca-ec11eb43cbac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score  0.7266666666666668\n",
            "\n",
            "Best estimator  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold(threshold=0.1)),\n",
            "                ('scaler', StandardScaler()), ('sampler', RandomOverSampler()),\n",
            "                ('knn',\n",
            "                 KNeighborsClassifier(metric='manhattan', n_jobs=-1,\n",
            "                                      n_neighbors=19))])\n"
          ]
        }
      ],
      "source": [
        "# GridSearch & f1-score\n",
        "estimator = GridSearchCV(pipe_knn[11], dict(selector__threshold=vthreshold,scaler = scalers,knn__metric = ['manhattan'],knn__n_neighbors = n_neighbors), cv=10, scoring='f1', n_jobs=-1)\n",
        "estimator.fit(train, train_labels)\n",
        "print(\"Best Score \",estimator.best_score_)\n",
        "print(\"\")\n",
        "print(\"Best estimator \", estimator.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNuX4PHkQ_eH",
        "outputId": "2502363f-537d-45e7-8f6f-9233366761f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kNN Classifier Best Parameters: {'knn__metric': 'manhattan', 'knn__n_neighbors': 19, 'scaler': StandardScaler(), 'selector__threshold': 0.1} \n",
            "\n",
            "F1-Score: 0.5333333333333333\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "knn_best = estimator.best_estimator_\n",
        "print(\"kNN Classifier Best Parameters:\", estimator.best_params_, \"\\n\")\n",
        "# f1-score\n",
        "knn_best.fit(train,train_labels)\n",
        "preds_knn_f1 = knn_best.predict(test)\n",
        "print(\"F1-Score:\", f1_score(test_labels, preds_knn_f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf4oNa4bn9sL"
      },
      "source": [
        "### Σχολιασμός:\n",
        "\n",
        "H μετρική manhattan επικράτησε καθώς στόχος ήταν η σύντομη εκτέλεση αφού για άλλες παραμέτρους θα ήταν σαφώς αυξημένος."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7oFUQuKoHFc"
      },
      "source": [
        "## **Λογιστική Παλινδρόμηση (Logistic Regression) (LR)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyAiSigJoOKi"
      },
      "outputs": [],
      "source": [
        "logistic = LogisticRegression(max_iter=500)\n",
        "pipe_lr = []\n",
        "\n",
        "pipe_lr.append(Pipeline(steps=[(\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('pca', pca), (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('sampler', raovs), (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('scaler', scaler),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('selector', selector),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('sampler', raovs),('pca', pca),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('scaler', scaler),('sampler', raovs),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('selector', selector),('sampler', raovs),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('selector', selector),('scaler', scaler),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('scaler', scaler),('sampler', raovs),('pca', pca),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('pca', pca),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('sampler', raovs),  (\"logistic\", logistic)],memory = 'tmp'))\n",
        "pipe_lr.append(Pipeline(steps=[('selector', selector),('scaler', scaler),('sampler', raovs),('pca', pca),  (\"logistic\", logistic)],memory = 'tmp'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ7RDFiloXxt"
      },
      "source": [
        "Θα χρησιμοποιηθεί το Pipeline 10 για f1-score και για accuracy. \n",
        "\n",
        "Για τις υπερπαραμέτρους, βρέθηκαν οι solvers ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ και καταλληλότερος φαίνεται να είναι ο liblinear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfbvmNOSoYz2",
        "outputId": "f9cfc796-3218-4348-e0d4-6a3f9da1b5ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'sampler', 'pca', 'logistic', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'sampler__random_state', 'sampler__sampling_strategy', 'sampler__shrinkage', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'logistic__C', 'logistic__class_weight', 'logistic__dual', 'logistic__fit_intercept', 'logistic__intercept_scaling', 'logistic__l1_ratio', 'logistic__max_iter', 'logistic__multi_class', 'logistic__n_jobs', 'logistic__penalty', 'logistic__random_state', 'logistic__solver', 'logistic__tol', 'logistic__verbose', 'logistic__warm_start'])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipe_lr[9].get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTX1816IoZt9"
      },
      "source": [
        "### Accuracy (Ορθότητα)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yytr-LjwoftA"
      },
      "outputs": [],
      "source": [
        "threshold = list(np.arange(0,1,0.1))\n",
        "scalers = [StandardScaler(), MinMaxScaler(),Normalizer(), MaxAbsScaler()]\n",
        "n_components = list(np.arange(4,30,2))\n",
        "penalty = ['l1', 'l2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIhI-J8UN3n",
        "outputId": "1ae17ce0-bd17-42a6-9e62-5fa22941fbaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score  0.82\n",
            "Best estimator  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('pca', PCA(n_components=4)),\n",
            "                ('logistic',\n",
            "                 LogisticRegression(max_iter=500, penalty='l1',\n",
            "                                    solver='liblinear'))])\n"
          ]
        }
      ],
      "source": [
        "# GridSearch & f1-score\n",
        "estimator = GridSearchCV(pipe_lr[10], dict(scaler = scalers,pca__n_components=n_components,logistic__solver = ['liblinear'],logistic__penalty = penalty), cv=10, scoring='accuracy', n_jobs=-1)\n",
        "estimator.fit(train, train_labels)\n",
        "print(\"Best Score \",estimator.best_score_)\n",
        "print(\"Best estimator \", estimator.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp_y0506UWGQ",
        "outputId": "0af10ca9-5d0f-4ad2-9321-91cbb2b9ed94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr Classifier Best Parameters: {'logistic__penalty': 'l1', 'logistic__solver': 'liblinear', 'pca__n_components': 4, 'scaler': StandardScaler()} \n",
            "\n",
            "Accuracy: 0.7391304347826086\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "lr_best = estimator.estimator\n",
        "print(\"lr Classifier Best Parameters:\", estimator.best_params_, \"\\n\")\n",
        "# accuracy\n",
        "lr_best.fit(train, train_labels)\n",
        "preds_lr_acc = lr_best.predict(test)\n",
        "print(\"Accuracy:\", accuracy_score(test_labels,preds_lr_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsGjCOMDosTZ"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hya36rqFot8w"
      },
      "outputs": [],
      "source": [
        "scalers = [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()]\n",
        "penalty = ['l1', 'l2']\n",
        "n_components = list(np.arange(4,30,2))\n",
        "threshold = list(np.arange(0,1,0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NKO_-gfUrW6",
        "outputId": "55df49f5-88a3-4221-b80f-f2bbbf5f3f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score  0.6933333333333334\n",
            "\n",
            "Best estimator  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold(threshold=0.1)),\n",
            "                ('scaler', StandardScaler()), ('pca', PCA(n_components=4)),\n",
            "                ('logistic',\n",
            "                 LogisticRegression(max_iter=500, solver='liblinear'))])\n"
          ]
        }
      ],
      "source": [
        "# GridSearch & f1-score\n",
        "estimator = GridSearchCV(pipe_lr[10], dict(selector__threshold=threshold,scaler = scalers,pca__n_components=n_components,logistic__solver = ['liblinear'],logistic__penalty = penalty), cv=10, scoring='f1', n_jobs=-1)\n",
        "estimator.fit(train, train_labels)\n",
        "print(\"Best Score \",estimator.best_score_)\n",
        "print(\"\")\n",
        "print(\"Best estimator \", estimator.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq6G0m2RUxFW",
        "outputId": "b5f7f636-1503-475e-89b4-28caf4d2a47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr Classifier Best Parameters: {'logistic__penalty': 'l2', 'logistic__solver': 'liblinear', 'pca__n_components': 4, 'scaler': StandardScaler(), 'selector__threshold': 0.1} \n",
            "\n",
            "F1-Score: 0.5714285714285714\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "lr_best = estimator.best_estimator_\n",
        "print(\"lr Classifier Best Parameters:\", estimator.best_params_, \"\\n\")\n",
        "# f1-score\n",
        "lr_best.fit(train, train_labels)\n",
        "preds_lr_f1 = lr_best.predict(test)\n",
        "print(\"F1-Score:\", f1_score(test_labels, preds_lr_f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fAM41-lpBxS"
      },
      "source": [
        "## **Παρουσίαση & Σύγκριση Επιδόσεων Βέλτιστων Αρχιτεκτονικών**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKYmz2J0pGWC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "fjXn4lU9pNlS",
        "outputId": "661278c8-4e21-46e7-b187-342acf67a9e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Estimator</th>\n",
              "      <th>Accuracy Optimized</th>\n",
              "      <th>Out-of-the-box difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes Classifier</td>\n",
              "      <td>0.7391304347826086</td>\n",
              "      <td>0.04347826086956519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>K-Nearest Neighbors</td>\n",
              "      <td>0.7391304347826086</td>\n",
              "      <td>0.04347826086956519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.7391304347826086</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Estimator  Accuracy Optimized Out-of-the-box difference\n",
              "0  Naive Bayes Classifier  0.7391304347826086       0.04347826086956519\n",
              "1     K-Nearest Neighbors  0.7391304347826086       0.04347826086956519\n",
              "2     Logistic Regression  0.7391304347826086                       0.0"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(np.array([['Naive Bayes Classifier',accuracy_score(test_labels,preds_gnb_acc) ,accuracy_score(test_labels,preds_gnb_acc) - class_accuracy['gnb']],\n",
        "                            ['K-Nearest Neighbors',accuracy_score(test_labels,preds_knn_acc),accuracy_score(test_labels,preds_knn_acc) - class_accuracy['knn']],\n",
        "                            ['Logistic Regression',accuracy_score(test_labels,preds_lr_acc),accuracy_score(test_labels,preds_lr_acc) - class_accuracy['lr']]]),\n",
        "                   columns=['Estimator', 'Accuracy Optimized', 'Out-of-the-box difference'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ZNdbnRKApt09",
        "outputId": "a80e2463-0935-46e3-dffa-ac655ae2bcdf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Estimator</th>\n",
              "      <th>F1-Score Optimized</th>\n",
              "      <th>Out-of-the-box difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes Classifier</td>\n",
              "      <td>0.5555555555555556</td>\n",
              "      <td>0.022222222222222254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>K-Nearest Neighbors</td>\n",
              "      <td>0.5333333333333333</td>\n",
              "      <td>0.07179487179487176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.5714285714285714</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Estimator  F1-Score Optimized Out-of-the-box difference\n",
              "0  Naive Bayes Classifier  0.5555555555555556      0.022222222222222254\n",
              "1     K-Nearest Neighbors  0.5333333333333333       0.07179487179487176\n",
              "2     Logistic Regression  0.5714285714285714                       0.0"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(np.array([['Naive Bayes Classifier',f1_score(test_labels,preds_gnb_f1) ,f1_score(test_labels,preds_gnb_f1) - class_f1['gnb']],\n",
        "                            ['K-Nearest Neighbors',f1_score(test_labels,preds_knn_f1),f1_score(test_labels,preds_knn_f1) - class_f1['knn']],\n",
        "                            ['Logistic Regression',f1_score(test_labels,preds_lr_f1),f1_score(test_labels,preds_lr_f1) - class_f1['lr']]]),\n",
        "                   columns=['Estimator', 'F1-Score Optimized', 'Out-of-the-box difference'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HND__5v5qXPD"
      },
      "source": [
        "### Σχολιασμός:\n",
        "\n",
        "Από τους πίνακες είναι φανερό ότι επιτεύχθηκε βελτιστοποίηση σε όλους τους ταξινομητές.\n",
        "\n",
        "Η μεγαλύτερη βελτιστοποίηση ήταν για την μετρική Accuracy ο kNN.\n",
        "\n",
        "Η μεγαλύτερη βελτιστοποίηση ήταν για την μετρική F1-Score ο kNN.\n",
        "\n",
        "Η βελτίωση σε όλους τους ταξινομητές ήταν αναμενόμενη αλλά τα ποσοστά είναι της τάξης του 1% - 5% και αυτό συμβαίνει διότι υπήρχαν ήδη καλά ποσοστά στο out-of-the-box για τα δεδομένα του data set.\n",
        "\n",
        "\n",
        "Επιπλέον, παρατηρείται ότι ο \"χειρότερος\" φαίνεται να είναι ο LR ενώ ο \"καλύτερος\" ο kNN. Επομένως, αυτός που προτείνεται είναι ο kNN καθώς παρουσιάζει την μεγαλύτερη βελτιστοποίηση τόσο για Accuracy όσο και για F1-Score."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}