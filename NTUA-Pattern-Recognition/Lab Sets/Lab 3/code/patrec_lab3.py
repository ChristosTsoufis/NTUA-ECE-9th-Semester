# -*- coding: utf-8 -*-
"""patrec-lab-3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LtvY7DXYZb7odAnyLLJ-QEvYcJNqdauU

## National Technical University of Athens
### School of Electrical & Computer Engineering
### Course: **Pattern Recognition**
##### *Flow S, 9th Semester, 2021-2022*

## Lab 3: Genre Recognition and Emotion Extraction from Music

<br>

##### Full Name: Christos Tsoufis
##### A.M.: 031 17 176

First of all, the data that will be used can be imported as shown in "Data Loading tutorial".
Specifically, to add the competition data:
1. Click File
2. Add or Upload data
3. Search by URL: https://www.kaggle.com/geoparslp/patreco3-multitask-affective-music

This Notebook consists of both Pre-Lab and Main-Lab.

The following cell is automatically created by Kaggle
"""

import os
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""## Description:

The goal of this lab is to recognize the genre and extract the emotions from spectrograms of music songs. We are given 2 datasets:

- Free Music Archive (FMA) genre that contains 3834 samples from 20 music genres.
- Multitask music dataset that contains 1497 samples with labels about the emotions such as valence, energy and danceability.

All samples came from spectrograms, that have been extracted from clips of 30 seconds from different songs. We will analyze the spectrograms using deep learning architectures such as Recurrent Neural Networks and Convolutional Neural Networks. The exercise is separated in 5 parts:

- Data analysis and familiarize with spectrograms.
- Implement classifiers about the music genre using the FMA dataset.
- Implement regression models for predicting valence, energy and danceability.
- Use of modern training techniques, such as transfer and multitask learning, to improve the previous results.
- Submit results in the Kaggle competition of the exercise (optional).

### Libraries and packages
"""

# PATTERN RECOGNITION
# LAB PROJECT #3

##########################################################################################
# Libraries & necessary packets
##########################################################################################

from random import sample
import librosa.display
import matplotlib.pyplot as plt

import numpy as np
import copy
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import Dataset
from torch.utils.data import SubsetRandomSampler, DataLoader
import re
from IPython.display import Image

import pickle
from torch.utils.data import Dataset
from torch.utils.data import TensorDataset, DataLoader
import torch.nn.functional as F
from sklearn.metrics import classification_report
from scipy.stats import spearmanr 

import torch
import copy
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels

import subprocess

from sklearn.metrics import classification_report

from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Sigmoid, BatchNorm2d,MSELoss
from torch.optim import Adam

from scipy.stats import spearmanr
from librosa.display import specshow

"""### Implementation of various functions

Define some useful functions for loading spectrograms and chromagrams
"""

def read_fused_spectrogram(spectrogram_file):
    spectrogram = np.load(spectrogram_file)
    return spectrogram.T

def read_mel_spectrogram(spectrogram_file):
    spectrogram = np.load(spectrogram_file)[:128]
    return spectrogram.T

def read_chromagram(spectrogram_file):
    spectrogram = np.load(spectrogram_file)[128:]
    return spectrogram.T

"""Train & Validation Splits"""

# TODO: Comment on how the train and validation splits are created.
# Answer: The input tables are shuffled and then subtables are appropriately extracted and put into the train and validation DataLoaders
# TODO: It's useful to set the seed when debugging but when experimenting ALWAYS set seed=None. Why?
# Answer: Constant means that we can reproduce our error when debugging but in experimenting we want numpy to choose 
# truly random subsets of data

# Train & Validation Splits:
# 1. shuffle the data in order to have them in a total random order*
# 2. set a seed in order the above random order to be the same while we optimize our models

def torch_train_val_split(
        dataset, batch_train, batch_eval,
        val_size=.2, shuffle=True, seed=None):
    
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split:]
    val_indices = indices[:val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    train_loader = DataLoader(dataset,
                              batch_size=batch_train,
                              sampler=train_sampler)
    val_loader = DataLoader(dataset,
                            batch_size=batch_eval,
                            sampler=val_sampler)
    return train_loader, val_loader

"""Define an encoder for the labels"""

class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])

"""Define a PaddingTransformer in order to convert all input sequences to the same length"""

# TODO: Comment on why padding is needed
# Answer: Padding is needed so that all samples have the same length
# padding is needing because we use batches and at the same time the #timesteps is different across our saples
class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[:self.max_length]

        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1

"""Define a Pytorch dataset for the 1st dataset"""

# Pytorch Dataset Class for creating the dataset
class SpectrogramDataset(Dataset):
    def __init__(self, path, class_mapping=None, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):
        t = 'train' if train else 'test'
        p = os.path.join(path, t)
        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = self.get_files_labels(self.index, class_mapping)
        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')

    def get_files_labels(self, txt, class_mapping):
        with open(txt, 'r') as fd:
            lines = [l.rstrip().split('\t') for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            label = l[1]
            if class_mapping:
                label = class_mapping[l[1]]
            if not label:
                continue
            # Kaggle automatically unzips the npy.gz format so this hack is needed
            _id = l[0].split('.')[0]
            npy_file = '{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            labels.append(label)
        return files, labels

    def __getitem__(self, item):
        # TODO: Inspect output and comment on how the output is formatted
        # Answer: Return a tuple in the form (padded_feats, label, length)
        l = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l

    def __len__(self):
        return len(self.labels)

"""LSTM  Implementation (from Lab 2)"""

class BasicLSTM(nn.Module):
    def __init__(self, input_dim, rnn_size, output_dim, num_layers, bidirectional=False, dropout = 0):
        super(BasicLSTM, self).__init__()
        self.bidirectional = bidirectional
        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size
        self.lstm    = nn.LSTM(input_dim, self.feature_size, num_layers, bidirectional = bidirectional, dropout = dropout, batch_first = True)
        self.linear  = nn.Linear(self.feature_size, out_features = output_dim)
        self.softmax = nn.LogSoftmax(dim = -1)

    def forward(self, x, lengths):
        """
            x : 3D numpy array of dimension N x L x D
                N: batch index
                L: sequence index
                D: feature index

            lengths: N x 1
        """
        batch_outputs, _ = self.lstm(x)
        last_outputs  = self.last_timestep(batch_outputs, lengths, self.bidirectional)
        predictions   = self.softmax(self.linear(last_outputs).squeeze(dim=-1))
        return predictions

    def last_timestep(self, outputs, lengths, bidirectional=False):
        """
            Returns the last output of the LSTM taking into account the zero padding
        """
        if bidirectional:
            forward, backward = self.split_directions(outputs)
            last_forward = self.last_by_index(forward, lengths)
            last_backward = backward[:, 0, :]
            # Concatenate and return - maybe add more functionalities like average
            return torch.cat((last_forward, last_backward), dim=-1)

        else:
            return self.last_by_index(outputs, lengths)

    @staticmethod
    def split_directions(outputs):
        direction_size = int(outputs.size(-1) / 2)
        forward = outputs[:, :, :direction_size]
        backward = outputs[:, :, direction_size:]
        return forward, backward

    @staticmethod
    def last_by_index(outputs, lengths):
        # Index of the last output for each sequence.
        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),
                                               outputs.size(2)).unsqueeze(1)
        return outputs.gather(1, idx).squeeze()

"""Function that evaluates a model against a dataset (expected to be a torch dataset)"""

def eval_dataset(model, dataloader):
    loss = nn.CrossEntropyLoss()
    predictions = []
    true_labels = []

    with torch.no_grad():
        total_loss = 0
        for i, data in enumerate(dataloader):
            X_batch, y_batch, lengths_batch = data
            y_pred = model(X_batch.float().to(device), lengths_batch.to(device))
            L = loss(y_pred.float(), y_batch.to(device))
            total_loss += L
            predictions = np.concatenate((predictions,np.argmax(y_pred.cpu(), 1)))
            true_labels = np.concatenate((true_labels, y_batch))

    return total_loss/(i+1), predictions, true_labels

"""LSTM training"""

def train(model,
          train_dataloader,
          val_dataloader,
          epochs = 20,
          learning_rate = 1e-5,
          momentum = 0.73,
          weight_regularization = 0,
          gamma = 1/2,
          step_size = 5,
          early_stopping = False,
          invscaling = False,
          verbose = False,
          optimizer_type = 'adam'):

    loss = nn.CrossEntropyLoss() #nn.MSELoss(reduction = 'mean')
    
    scheduler = None
    
    if optimizer_type == 'adam':
        optimizer = optim.Adam(model.parameters(), lr = learning_rate)
    
    else:
        optimizer   = optim.SGD(model.parameters(),
                                lr = learning_rate,
                                momentum = momentum,
                                weight_decay = weight_regularization
                                )
        scheduler   = optim.lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)
    
    training_loss   = []
    validation_loss = []
    best_loss  = None
    best_model = None
    
    if verbose:
        print("==========================================")

    val_loss,   _, _ = eval_dataset(model, val_dataloader)
    train_loss, _, _ = eval_dataset(model, train_dataloader)
    
    if verbose:
        print(f'Training   loss before training: {train_loss:.8f}')
        print(f'Validation loss before training: {val_loss:.8f}')

    validation_loss.append(val_loss)
    training_loss.append(train_loss)

    loss_increasing = 0
    
    pbar = tqdm(range(epochs))
    for epoch in pbar:
        total_loss = 0
        for index, data in enumerate(train_dataloader):
            X_batch, y_batch, lengths_batch = data
            y_pred = model(X_batch.float().to(device), lengths_batch.to(device))
            L      = loss(y_pred.float(), y_batch.to(device))
            total_loss += L.item()

            optimizer.zero_grad()
            L.backward()
            optimizer.step()
            
            if invscaling:
                scheduler.step()

        avg_loss = total_loss / (index+1)
        val_loss,   _, _ = eval_dataset(model, val_dataloader)

        validation_loss.append(val_loss)
        training_loss.append(avg_loss)
        
        if verbose:
            print(f'Epoch {epoch}')
            print(f'Training   Loss: {avg_loss:.8f}')
            print(f'Validation Loss: {val_loss:.8f}')
        
        pbar.set_description(f'Training Loss: {avg_loss:.5f}, Validation Loss: {val_loss:.5f}')

        if( best_loss is None or val_loss < best_loss ):
            best_loss = val_loss
            best_model = copy.deepcopy(model.state_dict())

        if early_stopping:
            # Checking if the model is overfitting the training set
            # or if the validation loss is climbing
            
            # Overfitting
            if avg_loss * 2 < val_loss: 
                break

            if validation_loss[:-1] > validation_loss[:-2]:
                loss_increasing += 1
            else:
                loss_increasing = 0

            if loss_increasing >= 5:
                break
                
    if verbose:
        print("==========================================")
    
    return best_model, training_loss, validation_loss

"""Function for overfitting one batch"""

def overfit_one_batch(model, dataloader, batch_size, epochs = 50, learning_rate = 1e-2, momentum = 0.73, invscaling = False, step_size = 50, gamma = 1/2):
    loss        = nn.CrossEntropyLoss()
    optimizer   = optim.SGD(model.parameters(), lr = learning_rate, momentum = momentum)
    scheduler   = optim.lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)
    
    best_accuracy = -1
     
    for index, data in enumerate(dataloader):
        X_batch, y_batch, lengths_batch = data
            
        # take a small subset of the batch
        X_batch = X_batch[:batch_size]
        y_batch = y_batch[:batch_size]
        lengths_batch = lengths_batch[:batch_size]
 
        
        pbar = tqdm(range(epochs))
        for epoch in pbar:
            
            y_pred = model(X_batch.float().to(device), lengths_batch.to(device))
            L      = loss(y_pred.float(), y_batch.to(device))
            batch_loss   = L.item()

            optimizer.zero_grad()
            L.backward()
            optimizer.step()
            if invscaling:
                scheduler.step()
            
            predicted_labels  = np.argmax(y_pred.cpu().detach().numpy(), 1)
            accuracy = accuracy_score(y_batch.cpu(), predicted_labels)
            
            
            pbar.set_description(f'Batch Loss = {batch_loss:.6f}, Batch Accuracy = {accuracy:.4f}')
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
            
            if best_accuracy == 1:
                break
        
        break
    
    return best_accuracy

"""CNN Implementation"""

class CNN(Module):   
    def __init__(self,n_classes=10,classification=1):
        super(CNN, self).__init__()
        self.classification = classification
        self.cnn_layers = Sequential(
            # layer 1
            Conv2d(1, 128, kernel_size=5, stride=1, padding=2),
            BatchNorm2d(128),
            ReLU(inplace=True),
            MaxPool2d(kernel_size=2, stride=2),
            # layer 2
            Conv2d(128, 64, kernel_size=5, stride=1, padding=2),
            BatchNorm2d(64),
            ReLU(inplace=True),
            MaxPool2d(kernel_size=2, stride=2),
            # layer 3
            Conv2d(64, 32, kernel_size=5, stride=1, padding=2),
            BatchNorm2d(32),
            ReLU(inplace=True),
            MaxPool2d(kernel_size=2, stride=2),
            # layer 4
            Conv2d(32, 8, kernel_size=5, stride=1, padding=2),
            BatchNorm2d(8),
            ReLU(inplace=True),
            MaxPool2d(kernel_size=2, stride=2),
        )
        if classification == 1:
            self.fc = Sequential(
                Linear(8 * 8 * 8, n_classes)
            )
        else:
            self.fc = Sequential(
                Linear(8 * 6 * 8, n_classes)
            )
            self.activation = Sigmoid()
    def forward(self, x):
        x = self.cnn_layers(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        if self.classification == 0:
            x = self.activation(x)
        return x

"""Regression Spectrogram Dataset Architecture"""

class RegressionSpectrogramDataset(Dataset):
    def __init__(self, path, class_mapping=None, train=True, max_length=-1, attr=1, read_spec_fn=read_fused_spectrogram):
        t = 'train' if train else 'test'
        p = os.path.join(path, t)
        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, self.labels = self.get_files_labels(self.index, attr)
        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.labels = np.array(self.labels).astype('double')
        #self.label_transformer = LabelTransformer()
        #if isinstance(labels, (list, tuple)):
        #    self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')

    def get_files_labels(self, txt, attr):
        with open(txt, 'r') as fd:
            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]
        files, valences = [], []
        for l in lines:
            valence = l[attr]
            if valence:
                label = valence
            if not label:
                continue
            # Kaggle automatically unzips the npy.gz format so this hack is needed
            _id = l[0].split('.')[0]
            npy_file = '{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            valences.append(valence)
        return files, valences

    def __getitem__(self, item):
        # TODO: Inspect output and comment on how the output is formatted
        l = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l

    def __len__(self):
        return len(self.labels)

def class_train(model, train_loader, val_loader, n_epochs=100):
    train_acc, val_acc = [], []
    max_acc = 0
    
    for epoch in range(n_epochs):
        model.train()
        for data, labels, _ in train_loader_beat_mel:
            data = data.cuda()
            labels = labels.cuda()
            data = data.view(-1, 1, 129, 128).double()
            out = model(data)
            loss = criterion(out, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
        acc = eval(model, val_loader_beat_mel)
        train_acc.append(eval(model, train_loader_beat_mel))
        val_acc.append(acc)

        # Save the Best Model 

        if acc > max_acc:
            max_acc = acc
            torch.save(model, 'model.ckpt')
        
        if ((epoch + 1) % 2 == 0):
            print('Validation Accuracy after ' + str(epoch+1) + ' EPOCHS: %.4f' % acc)

    return train_acc, val_acc

"""Evaluation and Prediction of a model"""

def eval(model, loader):    
    y, y_pred = predict(model, loader)
    return accuracy_score(y, y_pred)

def predict(model, loader): 
    model.eval()
    y_pred = []
    y = []
    with torch.no_grad():
        for data, labels, _ in loader:
            data = data.cuda()
            labels = labels.cuda()
            data = data.view(-1,1,129,128).double()
            out = model(data)
            _, pred = torch.max(out.data, 1)
            
            y_pred = np.concatenate((y_pred, pred.cpu().numpy()))
            y = np.concatenate((y, labels.cpu().numpy()))
            
    return y, y_pred

"""Function for Confusion matrix """

def plot_confusion_matrix( y_true, y_pred, fig, ax, allClasses, normalize=False, title=None, cmap=plt.cm.Blues):
        """
        This function prints and plots the confusion matrix.
        Normalization can be applied by setting `normalize=True`.
        """
        if not title:
            if normalize:
                title = 'Normalized confusion matrix'
            else:
                title = 'Confusion matrix, without normalization'

        # Compute confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        # Only use the labels that appear in the data
        classes = [ elem for elem in unique_labels(y_true, y_pred) if elem in allClasses]
        if normalize:
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
        ax.figure.colorbar(im, ax=ax)
        #show all the ticks
        ax.set(xticks=np.arange(cm.shape[1]),
               yticks=np.arange(cm.shape[0]),
               # ... and label them with the respective list entries
               xticklabels=classes, yticklabels=classes,
               title=title,
               ylabel='True label',
               xlabel='Predicted label')

        # Rotate the tick labels and set their alignment.
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
                 rotation_mode="anchor")

        # Loop over data dimensions and create text annotations.
        fmt = '.2f' if normalize else 'd'
        thresh = cm.max() / 2.
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                ax.text(j, i, format(cm[i, j], fmt),
                        ha="center", va="center",
                        color="white" if cm[i, j] > thresh else "black")
        fig.tight_layout()
        return ax

"""Function for Spearman implementation"""

def spearman(net, loader):
    y, y_pred = predict(net, loader)
    rho, _ = spearmanr(y, y_pred)
    return rho

def spearman_lstm(net, loader):
    y, y_pred = predict_lstm(net, loader)
    rho, _ = spearmanr(y, y_pred)
    return rho

def reg_train_cnn(model, train_loader, val_loader, task, n_epochs):
    
    max_score = 0
    total_loss = []
    
    for epoch in range(n_epochs):

        model.train()
        epoch_loss = []

        for data, labels, _ in train_loader:

            data = data.cuda()
            labels = labels.cuda()
            
            data = data.view(-1, 1, 104, 128).double()
            out = model(data)
            out = out.squeeze()
            loss = regr_criterion(out, labels.double())
            epoch_loss.append(loss.cpu().detach().numpy())
            regr_optimizer.zero_grad()
            loss.backward()
            regr_optimizer.step()
        
        total_loss.append(np.mean(epoch_loss))
        
        if ((epoch + 1) % 1 == 0):
            score = spearman(model, val_loader)
            
            # Save the Best Model 
            
            if score > max_score:
                max_score = score
                print('Spearman Correlation Coefficient after ' + str(epoch+1) + ' EPOCHS: %.4f ' % max_score)
                torch.save(model, task + '_model.ckpt')
                
    return total_loss

def reg_train_lstm(model, train_loader, val_loader, task, n_epochs):
    
    max_score = 0
    total_loss = []
    
    for epoch in range(n_epochs):

        model.train()
        epoch_loss = []

        for data, labels, lengths in train_loader:

            data = data.cuda()
            labels = labels.cuda()
            lengths = lengths.cuda()
            out = model(data, lengths)
            out = out.squeeze()
            loss = regr_criterion(out, labels.double())
            epoch_loss.append(loss.cpu().detach().numpy())
            lstm_optimizer.zero_grad()
            loss.backward()
            lstm_optimizer.step()
        
        total_loss.append(np.mean(epoch_loss))
        
        if ((epoch + 1) % 1 == 0):
            score = spearman_lstm(model, val_loader)
            
            # Save the Best Model 
            
            if score > max_score:
                max_score = score
                print('Spearman Correlation Coefficient after ' + str(epoch+1) + ' EPOCHS: %.4f ' % max_score)
                torch.save(model, task + '_model.ckpt')
                
    return total_loss

"""CNN prediction"""

def predict(model, loader):
    model.eval()
    y_pred = []
    y = []
    with torch.no_grad():
        for data, labels, _ in loader:
            data = data.cuda()
            labels = labels.cuda()
            data = data.view(-1,1,104,128).double()
            out = model(data)
            out = out.squeeze().cpu().numpy()
            
            y_pred = np.concatenate((y_pred, out))
            y = np.concatenate((y, labels.cpu().numpy()))
            
    return y, y_pred

"""LSTM prediction"""

def predict_lstm(model, loader):
    model.eval()
    y_pred = []
    y = []
    with torch.no_grad():
        for data, labels, lengths in loader:
            data = data.cuda()
            labels = labels.cuda()
            lengths = lengths.cuda()
            data = data.double()
            out = model(data, lengths)
            out = out.squeeze().cpu().numpy()
            
            y_pred = np.concatenate((y_pred, out))
            y = np.concatenate((y, labels.cpu().numpy()))
            
    return y, y_pred

"""Multitask learning functions"""

def multi_predict(test_model, loader):
    test_model.eval()
    y_pred = np.zeros((1,3))
    y = np.zeros((1,3))
    with torch.no_grad():
        for data, labels, _ in loader:
            data = data.cuda()              
            labels_reg = labels
            labels_reg = labels_reg.cuda()
            data = data.view(-1,1,104,128).double()
            out = test_model(data)
            out = out.squeeze().cpu().numpy().astype('double')
            labels_reg = labels_reg.squeeze().cpu().numpy().astype('double')
            y_pred = np.concatenate((y_pred, out),axis=0)
            y = np.concatenate((y, labels_reg),axis=0)
    return y[1:,:], y_pred[1:,:]

def multi_spearman(test_net, loader):
    res = []
    y, y_pred = multi_predict(test_net, loader)
    for attr in [0, 1, 2]:
        rho, _ = spearmanr(y_pred[:,attr],y[:,attr])
        res.append(rho)
    return res

def multi_reg_train(test_model, train_loader, val_loader, n_epochs):    
    max_score = 0
    total_loss = []
    for epoch in range(n_epochs):
        test_model.train()
        epoch_loss = []
        for data, labels, _ in train_loader:
            data = data.cuda()
            labels_valence = labels[:,0]
            labels_energy = labels[:,1]
            labels_dance = labels[:,2]
            labels_valence = labels_valence.cuda()
            labels_energy = labels_energy.cuda()
            labels_dance = labels_dance.cuda()
            data = data.view(-1, 1, 104, 128).double()
            out = test_model(data)
            multi_loss = multi_criterion(out[:,0] , labels_valence.double()) + multi_criterion(out[:,1] , labels_energy.double()) + multi_criterion(out[:,2] , labels_dance.double())
            epoch_loss.append(multi_loss.cpu().detach().numpy())
            multi_optimizer.zero_grad()
            multi_loss.backward()
            multi_optimizer.step()
        total_loss.append(np.mean(epoch_loss))
        if ((epoch + 1) % 4 == 0):
            s_1, s_2, s_3 = multi_spearman(multitask_model, val_loader)
            print('Spearman Scores after ' + str(epoch+1) + ' EPOCHS: %.4f' % s_1, '%.4f' % s_2, '%.4f' % s_3)
    return total_loss

"""## Prep - Lab

### Step 0: Familiarity with Kaggle kernels

Loading of train_labels.txt
"""

##########################################################################################
# Step 00
##########################################################################################
print("Step 00: Familiarity with Kaggle kernels\n")

"""### Step 01: Familiarity with spectrograms at mel scale"""

##########################################################################################
# Step 01
##########################################################################################
print("Step 01: Familiarity with spectrograms at mel scale\n")

genres_dict = {}

# (a)
with open("/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/" + 'train_labels.txt') as f:
    # first line header
    lines = f.readlines()[1:] 

for line in lines:
    # remove new lines
    line = line.replace('\n', '') 
    file_name, genre = line.split('\t')
    id = file_name.split('.')[0]
    if genre not in genres_dict.keys():
        # initialize the genre in the mapping
        genres_dict[genre] = [id] 
    else:
        genres_dict[genre].append(id)
        
# take 2 random different genres
sample_1 = sample(genres_dict.keys(), 1)[0]
while True:
    sample_2 = sample(genres_dict.keys(),1)[0]
    if sample_2 != sample_1 :
        break

spec_1_id = sample(genres_dict[sample_1],1)[0]
spec_2_id = sample(genres_dict[sample_2],1)[0]

spec_1 = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' + spec_1_id + '.fused.full.npy')
spec_2 = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' + spec_2_id + '.fused.full.npy')

print(spec_1.shape)

# (b)
mel_1, chroma_1 = spec_1[:128], spec_1[128:]
mel_2, chroma_2 = spec_2[:128], spec_2[128:]

# (c)
# plotting spectrogram
fig, ax = plt.subplots()
img = librosa.display.specshow(mel_1, x_axis='time', y_axis='linear', ax=ax)
ax.set(title='Spectrogram 1')
fig.colorbar(img, ax=ax, format="%+2.f dB")

fig, ax = plt.subplots()
img = librosa.display.specshow(mel_2, x_axis='time', y_axis='linear', ax=ax)
ax.set(title='Spectrogram 2')
fig.colorbar(img, ax=ax, format="%+2.f dB")

print("==================================================================\n")

"""### Step 02: Synchronization of spectrograms at the rythm of music (beat-synced spectrograms)"""

##########################################################################################
# Step 02
##########################################################################################
print("Step 02: Synchronization of spectrograms at the rythm of music (beat-synced spectrograms)\n")

# (a)
print("The shapes of the above spectrograms ")
print(mel_1.shape)
print(mel_2.shape)

# (b)
spec_1_beat = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/' + spec_1_id + '.fused.full.npy')
spec_2_beat = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/' + spec_2_id + '.fused.full.npy')
mel_1_beat, chroma_1_beat = spec_1_beat[:128], spec_1_beat[128:]
mel_2_beat, chroma_2_beat = spec_2_beat[:128], spec_2_beat[128:]

# plotting spectrogram
fig, ax = plt.subplots()
img = librosa.display.specshow(mel_1_beat, x_axis='time', y_axis='linear', ax=ax)
ax.set(title='Spectrogram 1 (beat sync)')
fig.colorbar(img, ax=ax, format="%+2.f dB")

fig, ax = plt.subplots()
img = librosa.display.specshow(mel_2_beat, x_axis='time', y_axis='linear', ax=ax)
ax.set(title='Spectrogram 2 (beat sync)')
fig.colorbar(img, ax=ax, format="%+2.f dB")

print("==================================================================\n")

"""* A spectrogram is a representation of the frequenies of a signal as it varies with time

* A beat-sync spectrogram is used in order to reduce the size of the samples (#timestemps) without losing useful information

* We can see that general form of the spectrum didn't change in both cases

### Step 03: Familiarity with chromagrams

#### Attempt 1
"""

##########################################################################################
# Step 03
##########################################################################################
print("Step 03: Familiarity with chromagrams\n")

fig, ax = plt.subplots()
img = librosa.display.specshow(chroma_1, y_axis='chroma', x_axis='time', ax=ax)
ax.set(title='Chromagram 1')
fig.colorbar(img, ax=ax)

fig, ax = plt.subplots()
img = librosa.display.specshow(chroma_2, y_axis='chroma', x_axis='time', ax=ax)
ax.set(title='Chromagram 2')
fig.colorbar(img, ax=ax)

fig, ax = plt.subplots()
img = librosa.display.specshow(chroma_1_beat, y_axis='chroma', x_axis='time', ax=ax)
ax.set(title='Chromagram 1 (beat sync)')
fig.colorbar(img, ax=ax)

fig, ax = plt.subplots()
img = librosa.display.specshow(chroma_2_beat, y_axis='chroma', x_axis='time', ax=ax)
ax.set(title='Chromagram 2 (beat sync)')
fig.colorbar(img, ax=ax)

print("==================================================================\n")

"""* A chromagram is a representation of the pitches (commolny 12 categories are being used) of a music signal as it varies with time

* A beat-sync chromagram is used in order to reduce the size of the samples (#timestemps) without losing useful information

* We can see that general form of the chromagram didn't change in both cases

### Step 04: Loading & Analysis of Data
"""

##########################################################################################
# Step 04
##########################################################################################
print("Step 04: Loading & Analysis of Data\n")

# (a) - (b)
# combine similar classes and remove underrepresented classes
class_mapping = {
    'Rock': 'Rock',
    'Psych-Rock': 'Rock',
    'Indie-Rock': None,
    'Post-Rock': 'Rock',
    'Psych-Folk': 'Folk',
    'Folk': 'Folk',
    'Metal': 'Metal',
    'Punk': 'Metal',
    'Post-Punk': None,
    'Trip-Hop': 'Trip-Hop',
    'Pop': 'Pop',
    'Electronic': 'Electronic',
    'Hip-Hop': 'Hip-Hop',
    'Classical': 'Classical',
    'Blues': 'Blues',
    'Chiptune': 'Electronic',
    'Jazz': 'Jazz',
    'Soundtrack': None,
    'International': None,
    'Old-Time': None
}

new_genres_dict = {}

for genre in genres_dict.keys():   
    ids = genres_dict[genre].copy()
    new_genre = class_mapping[genre]
    if (new_genre == None):
        continue
    if (new_genre in new_genres_dict.keys()):
        new_genres_dict[new_genre].append(ids)
    else:
        new_genres_dict[new_genre] = [ids]

# (c)
        
labels = genres_dict.keys()
hist = [len(genres_dict[genre]) for genre in genres_dict.keys()]

# label locations
x = np.arange(len(labels))
# width of the bars
width = 0.4  

fig = plt.figure(figsize=(12,9))
rects = plt.bar(x, hist, width)
plt.ylabel('Number of Samples')
plt.title('Before class mapping')
plt.xticks(x, labels, rotation=70)
plt.grid()
plt.show()

labels_new = new_genres_dict.keys()
hist_new = [len(new_genres_dict[genre]) for genre in new_genres_dict.keys()]

x = np.arange(len(labels_new))
width = 0.4

fig = plt.figure(figsize=(12,9))
rects = plt.bar(x, hist_new, width)
plt.ylabel('Number of Samples')
plt.title('After class mapping')
plt.xticks(x, labels_new, rotation=70)
plt.grid()
plt.show()

print("==================================================================\n")

"""#### Check for session"""

if torch.cuda.is_available():  
  dev = "cuda:0" 
else:  
  dev = "cpu"  
device = torch.device(dev)

print(dev)

"""### Step 05: Music Type Recognition with LSTM

Data loading process
* spectrograms and chromagrams are pre-computed and given within a specific forder structure at both the original and the beat-synced version 
* beat-synced version of our data reduces the data size while keeps most of the information
* we group some similar classes in order to make the classification task a bit easier
* we remove some under-represented classes because it's kind of impossible to learn something useful for them
* we padd our different-length sequences in order to use batches
* we shuffle our data because their initial order could not be random
* we use seed in order the above random order to be the same while we optimize our models
* we use a train-validation-test split
* we tranform our string labels into integers
"""

##########################################################################################
# Step 05
##########################################################################################
print("Step 05: Music Type Recognition with LSTM\n")

# First question of this Step can be seen above, in the "Various functions"

# (a)
# load datasets using the SpectogramDataset class
mel_specs = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',
         train=True,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_mel_spectrogram)
    
train_loader_mel, val_loader_mel = torch_train_val_split(mel_specs, 32 ,32, val_size=.33)
     
test_dataset_mel = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',
         train=False,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_mel_spectrogram)

test_loader_mel = DataLoader(test_dataset_mel, batch_size = 32)

# (a)
input_dimension  = 128
hidden_size      = 1024
output_dimension = 10
layers_num       = 2
bidirectional    = True

net5a = BasicLSTM(input_dimension, hidden_size, output_dimension, layers_num).to(device)

# overfit_one_batch(net5a, train_loader_mel, batch_size = 32, epochs = 500, learning_rate = 5e-2, invscaling = True, step_size = 100, gamma = 0.1)

_, y_pred, true_labels = eval_dataset(net5a, test_loader_mel)
print(f'Step 5a: Accuracy = {accuracy_score(true_labels, y_pred)}')
print()

# (b)
# load datasets using the SpectogramDataset class
beat_mel_specs = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',
         train=True,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_mel_spectrogram)
    
train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_specs, 128, 128, val_size=.33)
     
test_dataset_beat_mel = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',
         train=False,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_mel_spectrogram)

test_loader_beat_mel = DataLoader(test_dataset_beat_mel, batch_size = 128)

# (b)
input_dimension  = 128
hidden_size      = 512
output_dimension = 10
layers_num       = 1
bidirectional    = True

net5b = BasicLSTM(input_dimension, hidden_size, output_dimension, layers_num).to(device)

#overfit_one_batch(net5b, train_loader_beat_mel, batch_size = 32, epochs = 100, learning_rate = 5e-2, invscaling = True, step_size = 60, gamma = 0.1)

best_params, _, _ = train(net5b, train_loader_beat_mel, val_loader_beat_mel, learning_rate = 1e-4, epochs = 200)
params_path5b = './net5b_params.pickle'
net5b.load_state_dict(best_params)
torch.save(best_params, params_path5b)

_, y_pred5b, true_labels5b = eval_dataset(net5b, test_loader_beat_mel)
print(f'Step 5b: Accuracy = {accuracy_score(true_labels5b, y_pred5b)}')
print()

# (c)
# torch dataset using the beat synced chromagrams
beat_chroma = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',
         train=True,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_chromagram)

train_loader_beat_chroma, val_loader_beat_chroma = torch_train_val_split(beat_chroma, 128, 128, val_size=.33)

test_dataset_beat_chroma = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',
         train=False,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_chromagram)

test_loader_beat_chroma = DataLoader(test_dataset_beat_chroma, batch_size = 128)

# (c)
input_dimension  = 12
hidden_size      = 512
output_dimension = 10 
layers_num       = 1
bidirectional    = True

net5c = BasicLSTM(input_dimension, hidden_size, output_dimension, layers_num).to(device)

#overfit_one_batch(net5c, train_loader_beat_chroma, batch_size = 32, epochs = 1000, learning_rate = 5e-1, invscaling = True, step_size = 500, gamma = 0.1)

best_params, _, _ = train(net5c, train_loader_beat_chroma, val_loader_beat_chroma, learning_rate = 1e-4, epochs = 200)
params_path5c = './net5c_params.pickle'
net5c.load_state_dict(best_params)
torch.save(best_params, params_path5c)

_, y_pred, true_labels = eval_dataset(net5c, test_loader_beat_chroma)
print(f'Step 5c: Accuracy = {accuracy_score(true_labels, y_pred)}')
print()
print("==================================================================\n")

"""### Step 06: Model evaluation"""

##########################################################################################
# Step 06
##########################################################################################
print("Step 06: Model evaluation\n")

# (a) - (d)
_, y_pred5a, true_labels5a = eval_dataset(net5a, test_loader_mel)
print(f'Step 5a: Accuracy = {accuracy_score(true_labels5a, y_pred5a)}')

_, y_pred5b, true_labels5b = eval_dataset(net5b, test_loader_beat_mel)
print(f'Step 5b: Accuracy = {accuracy_score(true_labels5b, y_pred5b)}')

_, y_pred5c, true_labels5c = eval_dataset(net5c, test_loader_beat_chroma)
print(f'Step 5c: Accuracy = {accuracy_score(true_labels5c, y_pred5c)}')

# check for gpu
output = subprocess.check_output("nvidia-smi", shell=True)

print("Step 5a")
print(classification_report(true_labels5a, y_pred5a, zero_division = 0))

print("Step 5b")
print(classification_report(true_labels5b, y_pred5b, zero_division = 0))

print("Step 5c")
print(classification_report(true_labels5c, y_pred5c, zero_division = 0))

print("==================================================================\n")

"""##### 1) How a confusion matrix is getting filled?
1. We initialize the confuzion matrix of dimension CxC with zeros 
2. $ \forall{} \text{sample}$
    * we predict it's class, say $ ω_j $ $\:\:\:\:\:\:\:\:\:\:\:\:\:( ω_3 $ in the example)
    * and get it's true class, say $ ω_i $ $\:\:\:\:\:\:\:\:\:\: ( ω_2 $ in the example)
    * we add 1 to the element at $ (i,j) $  $\:\:\:\:\:\: ((2,3) $ in the example)

#### 2) TP / TN / FP / FN

It is answered in the report.

#### 3) accuracy / precision / recall / f1 score

#### per class metrics
$ \:\:\:\: Precision_i = \frac{TP_i}{TP_i + FP_i} = \frac{\text{#this class true guesses}}{\text{#this class true guesses} + \text{#this class wrong guesses}}$
<br> $ \:\:\:\:\:\:\:\: \text{ when we predict a certain class, how precise are we?}$
<br><br>$ \:\:\:\: Recall_i = \frac{TP_i}{TP_i + FN_i} = \frac{\text{#this class true guesses}}{\text{#this class true guesses} + \text{#this class misses}}$
<br> $ \:\:\:\:\:\:\:\: \text{ when a certain class exists, how frequently we predicts it?}$
<br><br>$ \:\:\:\: \text{F1-}score_i = 2 * \frac{Precision_i * Recall_i}{Precision_i + Recall_i}$
<br> $ \:\:\:\:\:\:\:\:  \text{1. equals to the harmonic_mean}(Precision_i,Recall_i) \leq \text{average_mean}(Precision_i,Recall_i)$
<br> $ \:\:\:\:\:\:\:\:  \text{2. gives equal weight to precision and recall}$

<br>
#### overall metric
* Binary classification
$ \:\:\:\: Accuracy = \frac{TP + TN}{TP + FP + FN + TN}$
<br> $ \:\:\:\:\:\:\:\: \text{the proportion of correctly classified samples out of all the samples}$
* Multi-class classification
$ \:\:\:\: Accuracy = \frac{\sum_{i=1}^{C} TP_i}{ \text{#all guesses}}$
<br> $ \:\:\:\:\:\:\:\: \text{the proportion of correctly classified samples out of all the samples}$

#### 4) micro / macro averaged precision / recall / f1 score

Macro/micro averaged scores combine the above per-class scores in order to result in the classifier’s overall score (a signle number).

* micro: count the total TP, FN and FP by examining all the samples together 
* macro: arithmetic mean of the per-class scores
* weighted: weighted-average of the per-class scores. The weighting factor of each class is called "support" (the number of true instances of this class). Other factors can be used, too.


Note the following:
 * $ Precision\text{-}micro = Recall\text{-}micro = F1\text{-}micro = Accuracy $
 * macro-metrics does not take label imbalance into account.
 * weighted alters ‘macro’ to account for label imbalance,  F1-macro can result in an score that is not between precision and recall.

#### 5) When is it possible to have bih deviation between micro/macro f1 score and what does it mean?

The difference between F1-micro (= Accuracy) and F1-macro is shown above.
"""

y_true = [0]*75+[1]*25
y_pred = [0]*99+[1]

fig, ax= plt.subplots(1,1,figsize=(15,5))
plot_confusion_matrix(y_true, y_pred, fig, ax, allClasses=np.arange(3), title='F1-score vs Precision')
plt.show() #keep this printing order
print(classification_report(y_true, y_pred))

"""F1-micro = Accuracy happens to be relativly high, 76%<br>
but F1-macro has significantly lower value, 47% due to the low f1-score of the second class which is a result of it's very low Recall.

#### 6) Are three problems where precision is more interesting than recall and vice versa ? Is a good accuracy / f1 enough to choose a model in this case?


$ \:\:\:\: Precision >> Recall $
<br> $ \:\:\:\:\:\:\:\: \text{e.g. Email spam detection: the cost of False Positives is high (positive = spam),} $
<br> $ \:\:\:\:\:\:\:\:\:\:\:\:\:\:\: \text{meaning that the user might lose important emails}$

$ \:\:\:\: Recall >> Precision $                                
<br> $ \:\:\:\:\:\:\:\: \text{e.g. Sick Patient Detection: the cost of False Negatives is high (negative = healthy),}$
<br> $ \:\:\:\:\:\:\:\:\:\:\:\:\:\:\: \text{meaning that a sick patient, who predicted as healty, might lose their life}$

In the above cases, using Accuracy or an aggregated form of F1-score is not a meaningful choice.

## Main - Lab

### Step 07: 2D CNN
"""

##########################################################################################
# Step 07
##########################################################################################
print("Step 07: 2D CNN\n")

# load datasets using the SpectogramDataset class

specs_fused = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',
         train=True,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_fused_spectrogram)

train_loader, val_loader = torch_train_val_split(specs_fused, 32 ,32, val_size=.33)

test_loader = SpectrogramDataset(
     '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',
     train=False,
     class_mapping=class_mapping,
     max_length=-1,
     read_spec_fn=read_fused_spectrogram)

# define model
model = CNN()
model.double()

# define optimizer
optimizer = Adam(model.parameters(), lr=0.0001,weight_decay=1e-2)

# define loss function
criterion = CrossEntropyLoss()

# check if GPU is available
if torch.cuda.is_available():
    model = model.cuda()
    criterion = criterion.cuda()
    
print(model)

def class_train(model, train_loader, val_loader, n_epochs=100):
    train_acc, val_acc = [], []
    max_acc = 0
    
    for epoch in range(n_epochs):
        model.train()
        for data, labels, _ in train_loader_beat_mel:
            data = data.cuda()
            labels = labels.cuda()
            data = data.view(-1, 1, 129, 128).double()
            out = model(data)
            loss = criterion(out, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
        acc = eval(model, val_loader_beat_mel)
        train_acc.append(eval(model, train_loader_beat_mel))
        val_acc.append(acc)

        # Save the Best Model 

        if acc > max_acc:
            max_acc = acc
            torch.save(model, 'model.ckpt')
        
        if ((epoch + 1) % 2 == 0):
            print('Validation Accuracy after ' + str(epoch+1) + ' EPOCHS: %.4f' % acc)

    return train_acc, val_acc

def eval(model, loader):    
    y, y_pred = predict(model, loader)
    return accuracy_score(y, y_pred)

def predict(model, loader): 
    model.eval()
    y_pred = []
    y = []
    with torch.no_grad():
        for data, labels, _ in loader:
            data = data.cuda()
            labels = labels.cuda()
            data = data.view(-1,1,129,128).double()
            out = model(data)
            _, pred = torch.max(out.data, 1)
            
            y_pred = np.concatenate((y_pred, pred.cpu().numpy()))
            y = np.concatenate((y, labels.cpu().numpy()))
            
    return y, y_pred

n_epochs = 30
train_acc, val_acc = class_train(model, train_loader_beat_mel, val_loader_beat_mel, n_epochs)

plt.figure(figsize=(8,8))

epochs = [(i+1) for i in range(30)]

plt.plot(epochs, train_acc, label='Training Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')

plt.title('Training Statistics')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
#plt.xticks([epochs])
plt.legend()
plt.grid()

plt.show()

print("==================================================================\n")

net = torch.load("model.ckpt")

"""* **2D convolutions**: CNNs are the NNs for the images. Instead of letting each neuron to connect with every pixel, we strictly define each neuron to connect to a square-subarea of the image. Now, we use filters that slide across all the regions of the image trying to find a specific feature. Each filter correspond to several neurons that of course share the weights.<br><br>
* **Batch normalization:** Batch normalization is a technique to standardize the (direct) inputs of a network or the activations of the prior layers and aims to:
 * accelerate training and
 * provides some regularization, reducing generalization error<br><br>
* **ReLU activation**: ReLU activation
 * is a non-linear component that is definetely needed in order to be logical to use multiple layers and so, manage to learn complex things
 * doesn't saturate when input gets large
 * doesn’t have the vanishing gradient problem
 * is very quick to compute<br><br>
* **Max pooling**: Max pooling is a sample-based process which
 * aims to down-sample the input representation without losing the useful information
 * helps with the overfitting problem by providing an abstracted form of the representation

### Step 08: Assessment of emotion - behavior with regression
"""

##########################################################################################
# Step 08
##########################################################################################
print("Step 08: Assessment of emotion - behavior with regression\n")

# load datasets using the RegressionSpectrogramDataset class

specs_valence = RegressionSpectrogramDataset(
    '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
     train=True,
     max_length=-1,
     attr = 1,
     read_spec_fn=read_mel_spectrogram)

train_loader_valence, val_loader_valence = torch_train_val_split(specs_valence, 32 ,32, val_size=.33)

specs_energy = RegressionSpectrogramDataset(
    '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
     train=True,
     max_length=-1,
     attr = 2,
     read_spec_fn=read_mel_spectrogram)

train_loader_energy, val_loader_energy = torch_train_val_split(specs_energy, 32 ,32, val_size=.33)

specs_dance = RegressionSpectrogramDataset(
    '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
     train=True,
     max_length=-1,
     attr = 3,
     read_spec_fn=read_mel_spectrogram)

train_loader_dance, val_loader_dance = torch_train_val_split(specs_dance, 32 ,32, val_size=.33)

# define models
regr_model = CNN(1,0)
regr_model.double()

input_dimension  = 128
hidden_size      = 512
output_dimension = 1
layers_num       = 1
bidirectional    = True

net8_lstm = BasicLSTM(input_dimension, hidden_size, output_dimension, layers_num).to(device)
net8_lstm.double()

# define optimizer
regr_optimizer = Adam(regr_model.parameters(), lr=0.001,weight_decay=1e-3)

lstm_optimizer = Adam(net8_lstm.parameters(), lr=1e-5)

# define loss function
regr_criterion = MSELoss()

# check if GPU is available
if torch.cuda.is_available():
    regr_model = regr_model.cuda()
    
print(regr_model)

def spearman(net, loader):
    y, y_pred = predict(net, loader)
    rho, _ = spearmanr(y, y_pred)
    return rho

def spearman_lstm(net, loader):
    y, y_pred = predict_lstm(net, loader)
    rho, _ = spearmanr(y, y_pred)
    return rho

def reg_train_cnn(model, train_loader, val_loader, task, n_epochs):
    
    max_score = 0
    total_loss = []
    
    for epoch in range(n_epochs):

        model.train()
        epoch_loss = []

        for data, labels, _ in train_loader:

            data = data.cuda()
            labels = labels.cuda()
            
            data = data.view(-1, 1, 104, 128).double()
            out = model(data)
            out = out.squeeze()
            loss = regr_criterion(out, labels.double())
            epoch_loss.append(loss.cpu().detach().numpy())
            regr_optimizer.zero_grad()
            loss.backward()
            regr_optimizer.step()
        
        total_loss.append(np.mean(epoch_loss))
        
        if ((epoch + 1) % 1 == 0):
            score = spearman(model, val_loader)
            
            # Save the Best Model 
            
            if score > max_score:
                max_score = score
                print('Spearman Correlation Coefficient after ' + str(epoch+1) + ' EPOCHS: %.4f ' % max_score)
                torch.save(model, task + '_model.ckpt')
                
    return total_loss

def reg_train_lstm(model, train_loader, val_loader, task, n_epochs):
    
    max_score = 0
    total_loss = []
    
    for epoch in range(n_epochs):

        model.train()
        epoch_loss = []

        for data, labels, lengths in train_loader:

            data = data.cuda()
            labels = labels.cuda()
            lengths = lengths.cuda()
            out = model(data, lengths)
            out = out.squeeze()
            loss = regr_criterion(out, labels.double())
            epoch_loss.append(loss.cpu().detach().numpy())
            lstm_optimizer.zero_grad()
            loss.backward()
            lstm_optimizer.step()
        
        total_loss.append(np.mean(epoch_loss))
        
        if ((epoch + 1) % 1 == 0):
            score = spearman_lstm(model, val_loader)
            
            # Save the Best Model 
            
            if score > max_score:
                max_score = score
                print('Spearman Correlation Coefficient after ' + str(epoch+1) + ' EPOCHS: %.4f ' % max_score)
                torch.save(model, task + '_model.ckpt')
                
    return total_loss

def predict(model, loader):
    
    model.eval()
    
    y_pred = []
    y = []
    
    with torch.no_grad():
        for data, labels, _ in loader:
            data = data.cuda()
            labels = labels.cuda()
            data = data.view(-1,1,104,128).double()
            out = model(data)
            out = out.squeeze().cpu().numpy()
            
            y_pred = np.concatenate((y_pred, out))
            y = np.concatenate((y, labels.cpu().numpy()))
            
    return y, y_pred

def predict_lstm(model, loader):
    
    model.eval()
    
    y_pred = []
    y = []
    
    with torch.no_grad():
        for data, labels, lengths in loader:
            data = data.cuda()
            labels = labels.cuda()
            lengths = lengths.cuda()
            data = data.double()
            out = model(data, lengths)
            out = out.squeeze().cpu().numpy()
            
            y_pred = np.concatenate((y_pred, out))
            y = np.concatenate((y, labels.cpu().numpy()))
            
    return y, y_pred

# training for valence
total_loss = reg_train_cnn(regr_model, train_loader_valence, val_loader_valence, 'valence', 30)

plt.figure(figsize=(8,8))
plt.plot(total_loss)
plt.title('Total Loss: Valence')
plt.xlabel('Number of Epochs')
plt.ylabel('Mean Square Error')
plt.grid()
plt.show()

# training for energy
total_loss = reg_train_cnn(regr_model, train_loader_energy, val_loader_energy, 'energy', 30)

plt.figure(figsize=(8,8))
plt.plot(total_loss)
plt.title('Total Loss: Energy')
plt.xlabel('Number of Epochs')
plt.ylabel('Mean Square Error')
plt.grid()
plt.show()

# training for danceability
total_loss = reg_train_cnn(regr_model, train_loader_dance, val_loader_dance, 'dance', 30)

plt.figure(figsize=(8,8))
plt.plot(total_loss)
plt.title('Total Loss: Danceability')
plt.xlabel('Number of Epochs')
plt.ylabel('Mean Square Error')
plt.grid()
plt.show()

tasks = ['dance', 'energy', 'valance']
loaders = [(train_loader_dance, val_loader_dance), (train_loader_energy, val_loader_energy), (train_loader_valence, val_loader_valence)]

for task, loader in zip(tasks, loaders):
    train, val = loader
    total_loss = reg_train_lstm(net8_lstm, train, val, task, 50)
    
    plt.figure(figsize=(8,8))
    plt.plot(total_loss)
    plt.title(f'Total Loss: {task.capitalize()}')
    plt.xlabel('Number of Epochs')
    plt.ylabel('Mean Square Error')
    plt.grid()
    plt.show()

best_valence = torch.load("valence_model.ckpt")
best_energy = torch.load("energy_model.ckpt")
best_dance = torch.load("dance_model.ckpt")

print("==================================================================\n")

"""### Step 09: Transfer Learning"""

##########################################################################################
# Step 09
##########################################################################################
print("Step 09: Transfer Learning\n")

# already saved as net
print(net)

net.fc = Linear(8*6*8, 1)
net.activation = Sigmoid()
net = net.double()
regr_criterion = MSELoss()
regr_optimizer = Adam(net.parameters(), lr=0.001, weight_decay=1e-4)
if torch.cuda.is_available():
    net = net.cuda()
    regr_criterion = regr_criterion.cuda()
print(net)

reg_train_cnn(net, train_loader_valence, val_loader_valence, 'valence_new', 10)

print("==================================================================\n")

"""### Step 10: Multitask Learning"""

##########################################################################################
# Step 10
##########################################################################################
print("Step 10: Multitask Learning\n")

# load datasets using the RegressionSpectrogramDataset class
specs_comb = RegressionSpectrogramDataset(
    '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
     train=True,
     max_length=-1,
     attr = 0,
     read_spec_fn=read_mel_spectrogram)

train_loader_comb, val_loader_comb = torch_train_val_split(specs_comb, 32 ,32, val_size=.2)
datum = next(iter(train_loader_comb))
print('Data shape')
print(datum[0].shape)  # shape of data
print('Labels')
print(datum[1])  # labels in batch
print('Lengths')
print(datum[2])  # length of each element in batch

# define model
multi_model = CNN(3,0)
multi_model.double()

# define optimizer
multi_optimizer = Adam(multi_model.parameters(), lr=0.001,weight_decay=1e-3)

# define loss function
multi_criterion = MSELoss()

# check if GPU is available
if torch.cuda.is_available():
    multi_model = multi_model.cuda()
    multi_criterion = multi_criterion.cuda()
    
print(multi_model)

def multi_predict(test_model, loader):
    test_model.eval()
    y_pred = np.zeros((1,3))
    y = np.zeros((1,3))
    with torch.no_grad():
        for data, labels, _ in loader:
            data = data.cuda()              
            labels_reg = labels
            labels_reg = labels_reg.cuda()
            data = data.view(-1,1,104,128).double()
            out = test_model(data)
            out = out.squeeze().cpu().numpy().astype('double')
            labels_reg = labels_reg.squeeze().cpu().numpy().astype('double')
            y_pred = np.concatenate((y_pred, out),axis=0)
            y = np.concatenate((y, labels_reg),axis=0)
    return y[1:,:], y_pred[1:,:]

def multi_spearman(test_net, loader):
    res = []
    y, y_pred = multi_predict(test_net, loader)
    for attr in [0, 1, 2]:
        rho, _ = spearmanr(y_pred[:,attr],y[:,attr])
        res.append(rho)
    return res

def multi_reg_train(test_model, train_loader, val_loader, n_epochs):    
    max_score = 0
    total_loss = []
    for epoch in range(n_epochs):
        test_model.train()
        epoch_loss = []
        for data, labels, _ in train_loader:
            data = data.cuda()
            labels_valence = labels[:,0]
            labels_energy = labels[:,1]
            labels_dance = labels[:,2]
            labels_valence = labels_valence.cuda()
            labels_energy = labels_energy.cuda()
            labels_dance = labels_dance.cuda()
            data = data.view(-1, 1, 104, 128).double()
            out = test_model(data)
            multi_loss = multi_criterion(out[:,0] , labels_valence.double()) + multi_criterion(out[:,1] , labels_energy.double()) + multi_criterion(out[:,2] , labels_dance.double())
            epoch_loss.append(multi_loss.cpu().detach().numpy())
            multi_optimizer.zero_grad()
            multi_loss.backward()
            multi_optimizer.step()
        total_loss.append(np.mean(epoch_loss))
        if ((epoch + 1) % 4 == 0):
            s_1, s_2, s_3 = multi_spearman(multitask_model, val_loader)
            print('Spearman Scores after ' + str(epoch+1) + ' EPOCHS: %.4f' % s_1, '%.4f' % s_2, '%.4f' % s_3)
    return total_loss

# total_loss = multi_reg_train(multi_model, train_loader_comb, val_loader_comb, 30)
print("The line above prints the total loss. Remove comment to run if necessary.")
print("==================================================================\n")
